(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[48247],{22330:function(e,r,a){(window.__NEXT_P=window.__NEXT_P||[]).push(["/papers.ru",function(){return a(23106)}])},43677:function(e,r,a){"use strict";a.d(r,{Z:function(){return p}});var n=a(11527),i=a(50959),s=a(85274),t=a(5341);function o(e){return(0,n.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,n.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:r,className:a,...i}=e;return(0,n.jsx)("button",{className:(0,t.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",a),...i,children:r})};function h(e){return(0,n.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function d(e){return(0,n.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,n.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,n.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let g=e=>{let{getValue:r,...a}=e,[s,t]=(0,i.useState)(!1);(0,i.useEffect)(()=>{if(!s)return;let e=setTimeout(()=>{t(!1)},2e3);return()=>{clearTimeout(e)}},[s]);let o=(0,i.useCallback)(async()=>{t(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(r())}catch(e){console.error("Failed to copy!")}},[r]);return(0,n.jsx)(l,{onClick:o,title:"Copy code",tabIndex:0,...a,children:(0,n.jsx)(s?h:d,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},c=e=>{let{children:r,className:a,hasCopyCode:s=!0,filename:h,...d}=e,c=(0,i.useRef)(null),x=(0,i.useCallback)(()=>{let e=document.documentElement.dataset,r="nextraWordWrap"in e;r?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,n.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[h&&(0,n.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:h}),(0,n.jsx)("pre",{className:(0,t.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",h?"nx-pt-12 nx-pb-4":"nx-py-4",a),ref:c,...d,children:i.isValidElement(r)&&"code"===r.type?r.props.children:r}),(0,n.jsxs)("div",{className:(0,t.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",h?"nx-top-8":"nx-top-0"),children:[(0,n.jsx)(l,{onClick:x,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,n.jsx)(o,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),s&&(0,n.jsx)(g,{getValue(){var e,r;return(null===(e=null===(r=c.current)||void 0===r?void 0:r.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},x={logo:(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,n.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,n.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,s.ZR)();return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,n.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,n.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,n.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,n.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:c}};var p=x},23106:function(e,r,a){"use strict";a.r(r),a.d(r,{__toc:function(){return l}});var n=a(11527),i=a(55411),s=a(85274),t=a(43677);a(20492),a(95178);var o=a(82132);let l=[{depth:2,value:"Обзоры",id:"обзоры"},{depth:2,value:"Подходы",id:"подходы"},{depth:2,value:"Применения",id:"применения"},{depth:2,value:"Коллекции",id:"коллекции"}];function h(e){let r=Object.assign({h1:"h1",p:"p",h2:"h2",ul:"ul",li:"li",a:"a"},(0,o.a)(),e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.h1,{children:"Статьи"}),"\n",(0,n.jsx)(r.p,{children:"Ниже приведены последние статьи (отсортированные по дате публикации) о создании промптов для больших языковых моделей (LLM). Мы ежедневно/еженедельно обновляем список статей."}),"\n",(0,n.jsx)(r.h2,{id:"обзоры",children:"Обзоры"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.16938",children:"Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13860",children:"Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.13712",children:"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.08354",children:"Tool Learning with Foundation Models"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.06488",children:"One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.02020",children:"A Bibliometric Review of Large Language Models Research from 2017 to 2023"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.18223",children:"A Survey of Large Language Models"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.14725",children:"Nature Language Reasoning, A Survey"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07842",children:"Augmented Language Models: a Survey"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2301.00234",children:"A Survey for In-context Learning"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.10403",children:"Towards Reasoning in Large Language Models: A Survey"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.09597",children:"Reasoning with Language Model Prompting: A Survey"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2206.07682",children:"Emergent Abilities of Large Language Models"})," (Jun 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.13988",children:"A Taxonomy of Prompt Modifiers for Text-To-Image Generation"})," (Apr 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2107.13586",children:"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"})," (Jul 2021)"]}),"\n"]}),"\n",(0,n.jsx)(r.h2,{id:"подходы",children:"Подходы"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00369",children:"Focused Prefix Tuning for Controllable Text Generation"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19500",children:"Exploring Lottery Prompts for Pre-trained Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19339",children:"Less Likely Brainstorming: Using Language Models to Generate Alternative Hypotheses"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.20050",children:"Let's Verify Step by Step"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.18787",children:"Universality and Limitations of Prompt Tuning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.16896",children:"MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14564v1",children:"PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14992v1",children:"Reasoning with Language Model is Planning with World Model"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13733",children:"Self-Critique Prompting with Large Language Models for Inductive Instructions"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14106",children:"Better Zero-Shot Reasoning with Self-Adaptive Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14257",children:"Hierarchical Prompting Assists Large Language Model on Web Navigation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13246",children:"Interactive Natural Language Processing"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12740",children:"Can We Edit Factual Knowledge by In-Context Learning?"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12766",children:"In-Context Learning of Large Language Models Explained as Kernel Regression"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.04091v3",children:"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12907",children:"Meta-in-context learning in large language models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11860",children:"Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11426",children:"Post Hoc Explanations of Language Models Can Improve Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11186",children:"Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM Inference with Transferable Prompt"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11497",children:"TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11430",children:"TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11170",children:"Efficient Prompting via Dynamic In-Context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10998",children:"The Web Can Be Your Oyster for Improving Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10713",children:"Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10601",children:"Tree of Thoughts: Deliberate Problem Solving with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10649",children:"ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10276",children:"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09955",children:"CooK: Empowering General-Purpose Language Models with Modular and Collaborative Knowledge"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09731",children:'What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning'})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09993",children:"Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09656",children:"Satisfiability-Aided Language Models Using Declarative Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09137",children:"Pre-Training to Learn in Context"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.05970",children:"Boosted Prompt Ensembles for Large Language Models"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.05642",children:"Global Prompt Cell: A Portable Control Module for Effective Prompt"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.03843",children:"Why think step-by-step? Reasoning emerges from the locality of experience"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.03609",children:"Revisiting Automated Prompting: Are We Actually Doing Better?"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.01904",children:"REFINER: Reasoning Feedback on Intermediate Representations"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.11366",children:"Reflexion: an autonomous agent with dynamic memory and self-reflection"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17760",children:'CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society'})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17651v1",children:"Self-Refine: Iterative Refinement with Self-Feedback"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13824",children:"kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13283",children:"Visual-Language Prompt Tuning with Knowledge-guided Context Optimization"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13217",children:"Fairness-guided Few-shot Prompting for Large Language Models"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.11315",children:"Context-faithful Prompting for Large Language Models"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.10475",children:"Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.08518",children:"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.07320",children:"Model-tuning Via Prompts Makes NLP Models Adversarially Robust"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03922",children:"Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03628",children:"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03846",children:"Larger language models do in-context learning differently"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02913",children:"OpenICL: An Open-Source Framework for In-context Learning"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02909",children:"Dynamic Prompting: A Unified Framework for Prompt Tuning"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02861",children:"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02577",children:"Effectiveness of Data Augmentation for Prefix Tuning with Limited Data"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.01580",children:"Mixture of Soft Prompts for Controllable Data Generation"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02151",children:"Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.00293",children:"How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/pdf/2302.10198.pdf",children:"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14838",children:"EvoPrompting: Language Models for Code-Level Neural Architecture Search"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14691",children:"In-Context Instruction Learning"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.02676",children:"Chain of Hindsight Aligns Language Models with Feedback"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14045",children:"Language Is Not All You Need: Aligning Perception with Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12822",children:"Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12246",children:"Active Prompting with Chain-of-Thought for Large Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12173",children:"More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.11382",children:"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.11520",children:"Guiding Large Language Models via Directional Stimulus Prompting"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.11521",children:"How Does In-Context Learning Help Prompt Tuning?"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.09236",children:"Scalable Prompt Generation for Semi-supervised Learning with Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.09185",children:"Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07994",children:"\xc0-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08043",children:"GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07459",children:"The Capacity for Moral Self-Correction in Large Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.06868",children:"SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.05619",children:"Evaluating the Robustness of Discrete Prompts"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.05698",children:"Compositional Exemplars for In-context Learning"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.03668",children:"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.00923",children:"Multimodal Chain-of-Thought Reasoning in Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.00093",children:"Large Language Models Can Be Easily Distracted by Irrelevant Context"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.00618",children:"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2301.12314",children:"Progressive Prompts: Continual Learning for Language Models"})," (Jan 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2301.08721",children:"Batch Prompting: Efficient Inference with LLM APIs"})," (Jan 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.14024",children:"Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.08061",children:"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.08073",children:"Constitutional AI: Harmlessness from AI Feedback"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.04092",children:"Successive Prompting for Decomposing Complex Questions"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.09561v1",children:"Large Language Models are reasoners with Self-Verification"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.09251",children:"Discovering Language Model Behaviors with Model-Written Evaluations"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.06713",children:"Structured Prompting: Scaling In-Context Learning to 1,000 Examples"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.10435",children:"PAL: Program-aided Language Models"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.01910",children:"Large Language Models Are Human-Level Prompt Engineers"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.09527",children:"Ignore Previous Prompt: Attack Techniques For Language Models"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.07321",children:"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.09066",children:"Teaching Algorithmic Reasoning via In-context Learning"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.11875",children:"Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for",children:"Ask Me Anything: A simple strategy for prompting language models"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.01296",children:"Recitation-Augmented Language Models"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.03629",children:"ReAct: Synergizing Reasoning and Acting in Language Models"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.09150",children:"Prompting GPT-3 To Be Reliable"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.02406",children:"Decomposed Prompting: A Modular Approach for Solving Complex Tasks"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.01240v3",children:"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2209.02128",children:"Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples"})," (Sep 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2209.14610",children:"Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning"})," (Sep 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2209.11755",children:"Promptagator: Few-shot Dense Retrieval From 8 Examples"})," (Sep 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2208.03299",children:"Atlas: Few-shot Learning with Retrieval Augmented Language Models"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2207.05987",children:"DocPrompting: Generating Code by Retrieving the Docs"})," (July 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2206.02336",children:"On the Advance of Making Language Models Better Reasoners"})," (June 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.11916",children:"Large Language Models are Zero-Shot Reasoners"})," (May 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.11822",children:"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations"})," (May 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.00445",children:"MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning"})," (May 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://aclanthology.org/2022.acl-long.576/",children:"PPT: Pre-trained Prompt Tuning for Few-shot Learning"})," (Mqy 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.12390",children:"Toxicity Detection with Generative Prompt-based Inference"})," (May 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.01543",children:"Learning to Transfer Prompts for Text Generation"})," (May 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.03401",children:"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning"})," (May 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.13988",children:"A Taxonomy of Prompt Modifiers for Text-To-Image Generation"})," (Apr 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.06566",children:"PromptChainer: Chaining Large Language Model Prompts through Visual Programming"})," (Mar 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.11171",children:"Self-Consistency Improves Chain of Thought Reasoning in Language Models"})," (March 2022)"]}),"\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.02155",children:"Training language models to follow instructions with human feedback"})}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2202.12837",children:"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"})," (Feb 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2201.11903",children:"Chain of Thought Prompting Elicits Reasoning in Large Language Models"})," (Jan 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.00114",children:"Show Your Work: Scratchpads for Intermediate Computation with Language Models"})," (Nov 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.01691",children:"AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts"})," (Oct 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.08387",children:"Generated Knowledge Prompting for Commonsense Reasoning"})," (Oct 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.08207",children:"Multitask Prompted Training Enables Zero-Shot Task Generalization"})," (Oct 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2109.07830",children:"Reframing Instructional Prompts to GPTk's Language"})," (Sep 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2109.06977",children:"Design Guidelines for Prompt Engineering Text-to-Image Generative Models"})," (Sep 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://aclanthology.org/2021.acl-long.295",children:"Making Pre-trained Language Models Better Few-shot Learners"})," (Aug 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2104.08786",children:"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"})," (April 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://aclanthology.org/2021.eacl-main.316",children:"BERTese: Learning to Speak to BERT"})," (April 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2104.08691",children:"The Power of Scale for Parameter-Efficient Prompt Tuning"})," (April 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2102.07350",children:"Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"})," (Feb 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2102.09690",children:"Calibrate Before Use: Improving Few-Shot Performance of Language Models"})," (Feb 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2101.00190",children:"Prefix-Tuning: Optimizing Continuous Prompts for Generation"})," (Jan 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2101.00420",children:"Learning to Generate Task-Specific Adapters from Task Description"})," (Jan 2021)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2012.15723",children:"Making Pre-trained Language Models Better Few-shot Learners"})," (Dec 2020)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://aclanthology.org/2020.emnlp-main.105/",children:"Learning from Task Descriptions"})," (Nov 2020)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2010.15980",children:"AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts"})," (Oct 2020)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2005.14165",children:"Language Models are Few-Shot Learners"})," (May 2020)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know",children:"How Can We Know What Language Models Know?"})," (July 2020)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2001.08361",children:"Scaling Laws for Neural Language Models"})," (Jan 2020)"]}),"\n"]}),"\n",(0,n.jsx)(r.h2,{id:"применения",children:"Применения"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00784",children:"Interpretable Math Word Problem Solution Generation Via Step-by-step Planning"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00774",children:"In-Context Learning User Simulators for Task-Oriented Dialog Systems"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00739",children:"SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00618",children:"Effective Structured Prompting by Meta-Learning and Representative Verbalizer"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00526",children:"Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2306.00550",children:"Chain-Of-Thought Prompting Under Streaming Batch: A Case Study"})," (June 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19713",children:"Red Teaming Language Model Detectors with Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19835",children:"Deliberate then Generate: Enhanced Prompting Framework for Text Generation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19597",children:'What does the Failure to Reason with "Respectively" in Zero/Few-Shot Settings Tell Us about Language Models?'})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19426",children:"ScoNe: Benchmarking Negation Reasoning in Language Models With Fine-Tuning and In-Context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19308",children:"SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19234",children:"Grammar Prompting for Domain-Specific Language Generation with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19148",children:"Mitigating Label Biases for In-context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.18638",children:"Short Answer Grading Using One-shot Prompting and Text Similarity Scoring Model"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.19165",children:"Strategic Reasoning with Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.18869",children:"Dissecting Chain-of-Thought: A Study on Compositional In-Context Learning of MLPs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.18189",children:"Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.18170",children:"Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.18156",children:"Exploring Effectiveness of GPT-3 in Grammatical Error Correction: A Study on Performance and Controllability in Prompt-Based Methods"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17826",children:"NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17812",children:"Tab-CoT: Zero-shot Tabular Chain of Thought"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17680",children:"Evaluating GPT-3 Generated Explanations for Hateful Content Moderation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17653",children:"Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:["[Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning]",(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17373",children:"https://arxiv.org/abs/2305.17373"}),") (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17306",children:"Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17256",children:"Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17147",children:"Heterogeneous Value Evaluation for Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17104",children:"PromptNER: Prompt Locating and Typing for Named Entity Recognition"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13514v1",children:"Small Language Models Improve Giants by Rewriting Their Outputs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.15771v1",children:"On the Planning Abilities of Large Language Models -- A Critical Investigation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.16582",children:"Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12600v1",children:"PRODIGY: Enabling In-context Learning Over Graphs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.15525v1",children:"Large Language Models are Few-Shot Health Learners"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.16367",children:"Role-Play with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13299v1",children:"Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12744v1",children:"Fact-Checking Complex Claims with Program-Guided Reasoning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17126v1",children:"Large Language Models as Tool Makers"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13016v2",children:"Iterative Forward Tuning Boosts In-context Learning in Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.17390v1",children:"SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13246v1",children:"Interactive Natural Language Processing"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.02897v1",children:"An automatically discovered chain-of-thought prompt generalizes to novel models and datasets"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.08291v1",children:"Large Language Model Guided Tree-of-Thought"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.06983v1",children:"Active Retrieval Augmented Generation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12544v1",children:"A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.02317v1",children:"Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09800v1",children:"Mirages: On Anthropomorphism in Dialogue Systems"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.15324v1",children:"Model evaluation for extreme risks"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.04388v1",children:"Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.02466v1",children:"Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13723",children:"PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.04757v2",children:"Augmented Large Language Models with Parametric Knowledge Guiding"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13735",children:"Aligning Large Language Models through Synthetic Feedback"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13775",children:"Concept-aware Training Improves In-context Learning Ability of Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.05176v1",children:"FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13785",children:"Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13817",children:"Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13826",children:'"Is the Pope Catholic?" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures'})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13903",children:"Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13917",children:"Generating Data for Symbolic Language with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13972",children:"Make a Choice! Knowledge Base Question Answering with In-Context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14002",children:"Improving Language Models via Plug-and-Play Retrieval Feedback"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14006",children:"Multi-Granularity Prompts for Topic Shift Detection in Dialogue"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14045",children:"The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14057",children:"Can Language Models Understand Physical Concepts?"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14069",children:"Evaluating Factual Consistency of Summaries with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14128",children:"Dr.ICL: Demonstration-Retrieved In-context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14171",children:"Probing in Context: Toward Building Robust Classifiers via Probing Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14210",children:"Skill-Based Few-Shot Selection for In-Context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14215",children:"Exploring Chain-of-Thought Style Prompting for Text-to-SQL"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14233",children:"Enhancing Chat Language Models by Scaling High-quality Instructional Conversations"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14239",children:"On Learning to Summarize with Large Language Models as References"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14259",children:"Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14264",children:"Active Learning Principles for In-Context Learning with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14279",children:"Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14325",children:"Improving Factuality and Reasoning in Language Models through Multiagent Debate"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14323",children:"ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on\\ Chat-based Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14292",children:"WikiChat: A Few-Shot LLM-Based Chatbot Grounded with Wikipedia"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.14283",children:"Query Rewriting for Retrieval-Augmented Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13729",children:"Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13412",children:"Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13514",children:"Small Language Models Improve Giants by Rewriting Their Outputs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13626",children:"Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13660",children:"Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13669",children:"Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13068",children:"Making Language Models Better Tool Learners with Execution Feedback"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13073",children:"Text-to-SQL Error Correction with Language Models of Code"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13085",children:"Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13235",children:"SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13252",children:'"According to ..." Prompting Language Models Improves Quoting from Pre-Training Data'})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13264",children:"Prompt-based methods may underestimate large language models' linguistic generalizations"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13269",children:"Chain of Knowledge: A Framework for Grounding Large Language Models with Structured Knowledge Bases"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.13299",children:"Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12576",children:"Automated Few-shot Classification with Instruction-Finetuned Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12586",children:"Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12627",children:"MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12696",children:"Learning Interpretable Style Embeddings via Prompting LLMs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12723",children:"Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12744",children:"Fact-Checking Complex Claims with Program-Guided Reasoning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12749",children:"A Benchmark on Extremely Weakly Supervised Text Classification: Reconcile Seed Matching and Prompting Approaches"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12757",children:"This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12761",children:"Enhancing Cross-lingual Natural Language Inference by Soft Prompting with Multilingual Verbalizer"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12900",children:"Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12535",children:"Explaining How Transformers Use Context to Build Predictions"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12392",children:"PiVe: Prompting with Iterative Verification Improving Graph-based Generative Capability of LLMs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12217",children:"PromptNER: A Prompting Method for Few-shot Named Entity Recognition via k Nearest Neighbor Search"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12295",children:"Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11791",children:"Enhancing Few-shot NER with Prompt Ordering based Data Augmentation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11792",children:"Chain-of-thought prompting for responding to in-depth dialogue questions with LLM"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11853",children:"How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11991",children:"Evaluation of medium-large Language Models at zero-shot closed book generative question answering"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12077",children:"Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.12096",children:"Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11255",children:"Reasoning Implicit Sentiment with Chain-of-Thought Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11334",children:"Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11366",children:"AutoTrial: Prompting Language Models for Clinical Trial Design"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11738",children:"CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11759",children:"Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11790",children:"Prompting with Pseudo-Code Instructions"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11171",children:"TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11159",children:"Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11140",children:"Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11038",children:"Learning In-context Learning for Named Entity Recognition"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10907",children:"Take a Break in the Middle: Investigating Subgoals towards Hierarchical Script Generation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10866",children:"TEPrompt: Task Enlightenment Prompt Learning for Implicit Discourse Relation Recognition"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10847",children:"Large Language Models can be Guided to Evade AI-Generated Text Detection"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10613",children:"Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11095",children:"Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10679",children:"Think Outside the Code: Brainstorming Boosts Large Language Models in Code Generation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10142",children:"Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09770",children:"ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09645",children:"StructGPT: A General Framework for Large Language Model to Reason over Structured Data"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09617",children:"Towards Expert-Level Medical Question Answering with Large Language Models"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09612",children:"Large Language Models are Built-in Autoregressive Search Engines"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09335",children:"MsPrompt: Multi-step Prompt Learning for Debiasing Few-shot Event Detection"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09312",children:"Exploring the Impact of Layer Normalization for Zero-shot Neural Machine Translation"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09067",children:"SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09333",children:"Multi-modal Visual Understanding with Prompts for Semantic Information Disentanglement of Image"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09025",children:"Soft Prompt Decoding for Multilingual Dense Retrieval"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://ai.google/static/documents/palm2techreport.pdf",children:"PaLM 2 Technical Report"})," (May 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.06556",children:"Are LLMs All You Need for Task-Oriented Dialogue?"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.05973",children:"HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.05253",children:"Approximating Human Evaluation of Social Chatbots with Prompting"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.04616",children:"Automated Reading Passage Generation with OpenAI's Large Language Model"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.04358",children:"WebBrain: Learning to Generate Factually Correct Articles for Queries by Grounding on Large Web Corpus"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.04704",children:"Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.02819",children:"GPT detectors are biased against non-native English writers"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.03153",children:"Zero-Shot Next-Item Recommendation using Large Pretrained Language Models"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.02213",children:"Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.01295",children:"Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.01228",children:"Better Language Models of Code through Self-Improvement"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.01209",children:"PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction"})," (April)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"",children:"Assessing Language Model Deployment with Risk Cards"})," (April 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.00116",children:"Enhancing Large Language Models with Climate Resources"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17564",children:"BloombergGPT: A Large Language Model for Finance"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17408",children:"Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15846",children:"Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.16434",children:"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.16445",children:"Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15587",children:"Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.14375",children:"Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15413",children:"Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15441#",children:"Zero-shot Model Diagnosis"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13592",children:"Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13035",children:"SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.11455",children:"Large Language Models and Simple, Stupid Bugs"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.09325",children:"Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.08896",children:"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"})," (Mar 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.07142",children:"Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.05063",children:"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.05398",children:"MathPrompter: Mathematical Reasoning using Large Language Models"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.05400",children:"Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03199",children:"Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.01903",children:"Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.00815",children:"Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.00733",children:"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks"})," (March 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14233",children:"Goal Driven Discovery of Distributional Differences via Language Descriptions"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.13439",children:"Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14169",children:"TabGenie: A Toolkit for Table-to-Text Generation"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12449",children:"SGL-PT: A Strong Graph Learner with Graph Prompt Tuning"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12468",children:"Few-Shot Table-to-Text Generation with Prompt-based Adapter"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12692",children:"Language Models Are Few-shot Learners for Prognostic Prediction"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12784",children:"STA: Self-controlled Text Augmentation for Improving Text Classifications"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12813",children:"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.10916",children:"How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08961",children:"Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08068",children:"LabelPrompt: Effective Prompt-based Learning for Relation Classification"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.09236",children:"Language Model Crossover: Variation through Few-Shot Prompting"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08102",children:"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07459",children:"The Capacity for Moral Self-Correction in Large Language Models"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.04156",children:"Prompting for Multimodal Hateful Meme Classification"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.03269",children:"PLACES: Prompting Language Models for Social Conversation Synthesis"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.01441",children:"Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation"})," (Feb 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2301.12810",children:"Crawling the Internal Knowledge-Base of Language Models"})," (Jan 2023)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.02199",children:"Legal Prompt Engineering for Multilingual Legal Judgement Prediction"})," (Dec 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.15462",children:"Investigating Prompt Engineering in Diffusion Models"})," (Nov 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2209.09513v2",children:"Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"})," (Sep 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.15157",children:"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.14699",children:"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?"})," (Oct 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://aclanthology.org/2022.inlg-main.5",children:"Plot Writing From Scratch Pre-Trained Language Models"})," (July 2022)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2202.03629",children:"Survey of Hallucination in Natural Language Generation"})," (Feb 2022)"]}),"\n"]}),"\n",(0,n.jsx)(r.h2,{id:"коллекции",children:"Коллекции"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"https://github.com/Timothyxxx/Chain-of-ThoughtsPapers",children:"Chain-of-Thought Papers"})}),"\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"https://paperswithcode.com/task/prompt-engineering",children:"Papers with Code"})}),"\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"https://github.com/thunlp/PromptPapers#papers",children:"Prompt Papers"})}),"\n"]})]})}let d={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:r}=Object.assign({},(0,o.a)(),e.components);return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(h,{...e})}):h(e)},pageOpts:{filePath:"pages/papers.ru.mdx",route:"/papers",timestamp:1685913976e3,pageMap:[{kind:"Meta",locale:"ru",data:{index:"Промпт инжиниринг",introduction:"Введение",techniques:"Техники",applications:"Применение",models:"Модели",risks:"Риски и неправильное использование",papers:"Статьи",tools:"Инструменты",notebooks:"Notebooks",datasets:"Datasets",readings:"Дополнительные статьи",course:{title:"Курс по инженерии промптов",type:"page"},services:{title:"Услуги",type:"page"},about:{title:"О нас",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"ru"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"ru",data:{pal:"Program-Aided Language Models",generating:"Генерация данных",coding:"Генерация кода",workplace_casestudy:"Исследование по классификации",pf:"Функции в промпте"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"ru"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"ru"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"ru"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"ru"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"ru"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"ru"},{kind:"MdxPage",name:"course",route:"/course",locale:"ru"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"ru"},{kind:"MdxPage",name:"index",route:"/",locale:"ru"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"ru",data:{settings:"Настройки LLM",basics:"Основы промптинга",elements:"Элементы промпта",tips:"Общие советы по созданию промптов",examples:"Примеры промптов"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"ru"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"ru"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"ru"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"ru"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"ru"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"ru"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"ru",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"Коллекция LLM"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"ru"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"ru"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"ru"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"ru"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"ru"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"ru"}]},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"ru"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"ru"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"ru"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"ru",data:{adversarial:"Противоборствующий промптинг",factuality:"Фактичность",biases:"Предубеждения"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"ru"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"ru"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"ru"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"ru"},{kind:"MdxPage",name:"services",route:"/services",locale:"ru"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"ru",data:{zeroshot:"Zero-shot Prompting",fewshot:"Few-shot Prompting",cot:"Chain-of-Thought Prompting",consistency:"Self-Consistency",knowledge:"Generate Knowledge Prompting",tot:"Tree of Thoughts",rag:"Retrieval Augmented Generation",art:"Automatic Reasoning and Tool-use",ape:"Automatic Prompt Engineer",activeprompt:"Active-Prompt",dsp:"Directional Stimulus Prompting",react:"ReAct",multimodalcot:"Multimodal CoT",graph:"Graph Prompting"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"ru"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"ru"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"ru"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"ru"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"ru"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"ru"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"ru"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"ru"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"ru"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"ru"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"ru"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"ru"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"ru"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"ru"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"ru"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"ru"},{kind:"MdxPage",name:"models",route:"/models",locale:"en"}],flexsearch:{codeblocks:!0},title:"Статьи",headings:l},pageNextRoute:"/papers.ru",nextraLayout:s.ZP,themeConfig:t.Z};r.default=(0,i.j)(d)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=22330)}),_N_E=e.O()}]);