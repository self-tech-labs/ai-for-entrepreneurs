(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[11695],{34464:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/applications/workplace_casestudy.en",function(){return n(99914)}])},43677:function(e,t,n){"use strict";n.d(t,{Z:function(){return p}});var i=n(11527),r=n(50959),s=n(85274),a=n(5341);function o(e){return(0,i.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,i.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:t,className:n,...r}=e;return(0,i.jsx)("button",{className:(0,a.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",n),...r,children:t})};function d(e){return(0,i.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,i.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function c(e){return(0,i.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,i.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,i.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let h=e=>{let{getValue:t,...n}=e,[s,a]=(0,r.useState)(!1);(0,r.useEffect)(()=>{if(!s)return;let e=setTimeout(()=>{a(!1)},2e3);return()=>{clearTimeout(e)}},[s]);let o=(0,r.useCallback)(async()=>{a(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(t())}catch(e){console.error("Failed to copy!")}},[t]);return(0,i.jsx)(l,{onClick:o,title:"Copy code",tabIndex:0,...n,children:(0,i.jsx)(s?d:c,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},x=e=>{let{children:t,className:n,hasCopyCode:s=!0,filename:d,...c}=e,x=(0,r.useRef)(null),m=(0,r.useCallback)(()=>{let e=document.documentElement.dataset,t="nextraWordWrap"in e;t?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,i.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[d&&(0,i.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:d}),(0,i.jsx)("pre",{className:(0,a.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",d?"nx-pt-12 nx-pb-4":"nx-py-4",n),ref:x,...c,children:r.isValidElement(t)&&"code"===t.type?t.props.children:t}),(0,i.jsxs)("div",{className:(0,a.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",d?"nx-top-8":"nx-top-0"),children:[(0,i.jsx)(l,{onClick:m,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,i.jsx)(o,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),s&&(0,i.jsx)(h,{getValue(){var e,t;return(null===(e=null===(t=x.current)||void 0===t?void 0:t.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},m={logo:(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,i.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,i.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,i.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,i.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,s.ZR)();return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,i.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,i.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,i.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,i.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,i.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,i.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:x}};var p=m},99914:function(e,t,n){"use strict";n.r(t),n.d(t,{__toc:function(){return l}});var i=n(11527),r=n(55411),s=n(85274),a=n(43677);n(20492),n(95178);var o=n(82132);let l=[{depth:3,value:"Prompt Modifications Tested",id:"prompt-modifications-tested"},{depth:3,value:"Performance Impact of All Prompt Modifications",id:"performance-impact-of-all-prompt-modifications"}];function d(e){let t=Object.assign({h1:"h1",p:"p",a:"a",code:"code",ul:"ul",li:"li",h3:"h3",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td",em:"em",strong:"strong"},(0,o.a)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{children:"Graduate Job Classification Case Study"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://arxiv.org/abs/2303.07142",children:"Clavi\xe9 et al., 2023"}),' provide a case-study on prompt-engineering applied to a medium-scale text classification use-case in a production system. Using the task of classifying whether a job is a true "entry-level job", suitable for a recent graduate, or not, they evaluated a series of prompt engineering techniques and report their results using GPT-3.5 (',(0,i.jsx)(t.code,{children:"gpt-3.5-turbo"}),")."]}),"\n",(0,i.jsxs)(t.p,{children:["The work shows that LLMs outperforms all other models tested, including an extremely strong baseline in DeBERTa-V3. ",(0,i.jsx)(t.code,{children:"gpt-3.5-turbo"})," also noticeably outperforms older GPT3 variants in all key metrics, but requires additional output parsing as its ability to stick to a template appears to be worse than the other variants."]}),"\n",(0,i.jsx)(t.p,{children:"The key findings of their prompt engineering approach are:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"For tasks such as this one, where no expert knowledge is required, Few-shot CoT prompting performed worse than Zero-shot prompting in all experiments."}),"\n",(0,i.jsx)(t.li,{children:"The impact of the prompt on eliciting the correct reasoning is massive. Simply asking the model to classify a given job results in an F1 score of 65.6, whereas the post-prompt engineering model achieves an F1 score of 91.7."}),"\n",(0,i.jsx)(t.li,{children:"Attempting to force the model to stick to a template lowers performance in all cases (this behaviour disappears in early testing with GPT-4, which are posterior to the paper)."}),"\n",(0,i.jsxs)(t.li,{children:["Many small modifications have an outsized impact on performance.","\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"The tables below show the full modifications tested."}),"\n",(0,i.jsx)(t.li,{children:"Properly giving instructions and repeating the key points appears to be the biggest performance driver."}),"\n",(0,i.jsx)(t.li,{children:"Something as simple as giving the model a (human) name and referring to it as such increased F1 score by 0.6pts."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"prompt-modifications-tested",children:"Prompt Modifications Tested"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Short name"}),(0,i.jsx)(t.th,{children:"Description"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Baseline"}),(0,i.jsx)(t.td,{children:"Provide a a job posting and asking if it is fit for a graduate."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"CoT"}),(0,i.jsx)(t.td,{children:"Give a few examples of accurate classification before querying."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Zero-CoT"}),(0,i.jsx)(t.td,{children:"Ask the model to reason step-by-step before providing its answer."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"rawinst"}),(0,i.jsx)(t.td,{children:"Give instructions about its role and the task by adding to the user msg."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"sysinst"}),(0,i.jsx)(t.td,{children:"Give instructions about its role and the task as a system msg."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"bothinst"}),(0,i.jsx)(t.td,{children:"Split instructions with role as a system msg and task as a user msg."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"mock"}),(0,i.jsx)(t.td,{children:"Give task instructions by mocking a discussion where it acknowledges them."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"reit"}),(0,i.jsx)(t.td,{children:"Reinforce key elements in the instructions by repeating them."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"strict"}),(0,i.jsx)(t.td,{children:"Ask the model to answer by strictly following a given template."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"loose"}),(0,i.jsx)(t.td,{children:"Ask for just the final answer to be given following a given template."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"right"}),(0,i.jsx)(t.td,{children:"Asking the model to reach the right conclusion."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"info"}),(0,i.jsx)(t.td,{children:"Provide additional information to address common reasoning failures."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"name"}),(0,i.jsx)(t.td,{children:"Give the model a name by which we refer to it in conversation."})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"pos"}),(0,i.jsx)(t.td,{children:"Provide the model with positive feedback before querying it."})]})]})]}),"\n",(0,i.jsx)(t.h3,{id:"performance-impact-of-all-prompt-modifications",children:"Performance Impact of All Prompt Modifications"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{}),(0,i.jsx)(t.th,{children:"Precision"}),(0,i.jsx)(t.th,{children:"Recall"}),(0,i.jsx)(t.th,{children:"F1"}),(0,i.jsx)(t.th,{children:"Template Stickiness"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"Baseline"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"61.2"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"70.6"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"65.6"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"79%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"CoT"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"72.6"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"85.1"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"78.4"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"87%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"Zero-CoT"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"75.5"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"88.3"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"81.4"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"65%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"+rawinst"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"80"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"92.4"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"85.8"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"68%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"+sysinst"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"77.7"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"90.9"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"83.8"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"69%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"+bothinst"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"81.9"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"93.9"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"87.5"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"71%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"+bothinst+mock"}),(0,i.jsx)(t.td,{children:"83.3"}),(0,i.jsx)(t.td,{children:"95.1"}),(0,i.jsx)(t.td,{children:"88.8"}),(0,i.jsx)(t.td,{children:"74%"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"+bothinst+mock+reit"}),(0,i.jsx)(t.td,{children:"83.8"}),(0,i.jsx)(t.td,{children:"95.5"}),(0,i.jsx)(t.td,{children:"89.3"}),(0,i.jsx)(t.td,{children:"75%"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"+bothinst+mock+reit+strict"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"79.9"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"93.7"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"86.3"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:(0,i.jsx)(t.strong,{children:"98%"})})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"+bothinst+mock+reit+loose"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"80.5"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"94.8"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"87.1"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.em,{children:"95%"})})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"+bothinst+mock+reit+right"}),(0,i.jsx)(t.td,{children:"84"}),(0,i.jsx)(t.td,{children:"95.9"}),(0,i.jsx)(t.td,{children:"89.6"}),(0,i.jsx)(t.td,{children:"77%"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"+bothinst+mock+reit+right+info"}),(0,i.jsx)(t.td,{children:"84.9"}),(0,i.jsx)(t.td,{children:"96.5"}),(0,i.jsx)(t.td,{children:"90.3"}),(0,i.jsx)(t.td,{children:"77%"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"+bothinst+mock+reit+right+info+name"}),(0,i.jsx)(t.td,{children:"85.7"}),(0,i.jsx)(t.td,{children:"96.8"}),(0,i.jsx)(t.td,{children:"90.9"}),(0,i.jsx)(t.td,{children:"79%"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"+bothinst+mock+reit+right+info+name+pos"}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"86.9"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"97"})}),(0,i.jsx)(t.td,{children:(0,i.jsx)(t.strong,{children:"91.7"})}),(0,i.jsx)(t.td,{children:"81%"})]})]})]}),"\n",(0,i.jsx)(t.p,{children:"Template stickiness refers to how frequently the model answers in the desired format."})]})}let c={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,o.a)(),e.components);return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)},pageOpts:{filePath:"pages/applications/workplace_casestudy.en.mdx",route:"/applications/workplace_casestudy",timestamp:1680711958e3,pageMap:[{kind:"Meta",locale:"en",data:{index:"Prompt Engineering",introduction:"Introduction",techniques:"Techniques",applications:"Applications",models:"Models",risks:"Risks & Misuses",papers:"Papers",tools:"Tools",notebooks:"Notebooks",datasets:"Datasets",readings:"Additional Readings",course:{title:"Prompt Engineering Course",type:"page"},services:{title:"Services",type:"page"},about:{title:"About",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"en"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"en",data:{pal:"Program-Aided Language Models",generating:"Generating Data",synthetic_rag:"Generating Synthetic Dataset for RAG",generating_textbooks:"Tackling Generated Datasets Diversity",coding:"Generating Code",workplace_casestudy:"Graduate Job Classification Case Study",pf:"Prompt Function"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"en"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"en"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"en"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"en"},{kind:"MdxPage",name:"course",route:"/course",locale:"en"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"en"},{kind:"MdxPage",name:"index",route:"/",locale:"en"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"en",data:{settings:"LLM Settings",basics:"Basics of Prompting",elements:"Prompt Elements",tips:"General Tips for Designing Prompts",examples:"Examples of Prompts"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"en"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"en"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"en"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"en"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"en"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"en"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"en",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"LLM Collection"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"en"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"en"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"en"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"en"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"en"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"en"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"en"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"en"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"en"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"en"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"en",data:{adversarial:"Adversarial Prompting",factuality:"Factuality",biases:"Biases"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"en"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"en"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"en"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"en"},{kind:"MdxPage",name:"services",route:"/services",locale:"en"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"en",data:{zeroshot:"Zero-shot Prompting",fewshot:"Few-shot Prompting",cot:"Chain-of-Thought Prompting",consistency:"Self-Consistency",knowledge:"Generate Knowledge Prompting",tot:"Tree of Thoughts",rag:"Retrieval Augmented Generation",art:"Automatic Reasoning and Tool-use",ape:"Automatic Prompt Engineer",activeprompt:"Active-Prompt",dsp:"Directional Stimulus Prompting",react:"ReAct",multimodalcot:"Multimodal CoT",graph:"Graph Prompting"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"en"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"en"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"en"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"en"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"en"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"en"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"en"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"en"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"en"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"en"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"en"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"en"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"en"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"en"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"en"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"en"}],flexsearch:{codeblocks:!0},title:"Graduate Job Classification Case Study",headings:l},pageNextRoute:"/applications/workplace_casestudy.en",nextraLayout:s.ZP,themeConfig:a.Z};t.default=(0,r.j)(c)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=34464)}),_N_E=e.O()}]);