(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[60584],{68657:function(e,n,a){(window.__NEXT_P=window.__NEXT_P||[]).push(["/models/llama.es",function(){return a(77664)}])},72257:function(e,n){"use strict";n.Z={src:"/_next/static/media/llama-1.ced83624.png",height:744,width:1099,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAWUlEQVR42g1NSRLAMAjy/z9tp0lU1GyXwolhlTWnjz6roAozkvG9VSkB32vRJjn3wj0Qe29hpL1PZsBUe69MbY2iuClTrPgYbMINVAA550REElUAipdci/gB50hyS3ziQDEAAAAASUVORK5CYII=",blurWidth:8,blurHeight:5}},41667:function(e,n,a){"use strict";a.d(n,{w:function(){return s}});var t=a(11527),o=a(5341),i=a(76484),r=a.n(i);function s(e){let{src:n,alt:a,full:i}=e;return(0,t.jsx)("div",{className:(0,o.Z)("mt-6 -mb-4 flex justify-center overflow-hidden rounded-xl border dark:border-zinc-800",i?"bg-white":"bg-zinc-100"),children:(0,t.jsx)(r(),{src:n,alt:a,className:(0,o.Z)("w-auto select-none bg-white",i?"":"ring-1 ring-gray-200")})})}},43677:function(e,n,a){"use strict";a.d(n,{Z:function(){return m}});var t=a(11527),o=a(50959),i=a(85274),r=a(5341);function s(e){return(0,t.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,t.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:n,className:a,...o}=e;return(0,t.jsx)("button",{className:(0,r.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",a),...o,children:n})};function d(e){return(0,t.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function c(e){return(0,t.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,t.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,t.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let u=e=>{let{getValue:n,...a}=e,[i,r]=(0,o.useState)(!1);(0,o.useEffect)(()=>{if(!i)return;let e=setTimeout(()=>{r(!1)},2e3);return()=>{clearTimeout(e)}},[i]);let s=(0,o.useCallback)(async()=>{r(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(n())}catch(e){console.error("Failed to copy!")}},[n]);return(0,t.jsx)(l,{onClick:s,title:"Copy code",tabIndex:0,...a,children:(0,t.jsx)(i?d:c,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},x=e=>{let{children:n,className:a,hasCopyCode:i=!0,filename:d,...c}=e,x=(0,o.useRef)(null),p=(0,o.useCallback)(()=>{let e=document.documentElement.dataset,n="nextraWordWrap"in e;n?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,t.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[d&&(0,t.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:d}),(0,t.jsx)("pre",{className:(0,r.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",d?"nx-pt-12 nx-pb-4":"nx-py-4",a),ref:x,...c,children:o.isValidElement(n)&&"code"===n.type?n.props.children:n}),(0,t.jsxs)("div",{className:(0,r.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",d?"nx-top-8":"nx-top-0"),children:[(0,t.jsx)(l,{onClick:p,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,t.jsx)(s,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),i&&(0,t.jsx)(u,{getValue(){var e,n;return(null===(e=null===(n=x.current)||void 0===n?void 0:n.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},p={logo:(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,t.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,t.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,t.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,t.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,i.ZR)();return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,t.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,t.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,t.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,t.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,t.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,t.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:x}};var m=p},77664:function(e,n,a){"use strict";a.r(n),a.d(n,{__toc:function(){return u}});var t=a(11527),o=a(55411),i=a(85274),r=a(43677);a(20492),a(95178);var s=a(82132),l=a(41667),d=a(63622),c=a(72257);let u=[{depth:2,value:"LLaMA: Open and Efficient Foundation Language Models",id:"llama-open-and-efficient-foundation-language-models"},{depth:2,value:"\xbfQu\xe9 hay de nuevo?",id:"qu\xe9-hay-de-nuevo"},{depth:2,value:"Capacidades y resultados clave",id:"capacidades-y-resultados-clave"},{depth:2,value:"Referencias",id:"referencias"}];function x(e){let n=Object.assign({h2:"h2",p:"p",a:"a",em:"em",ul:"ul",li:"li"},(0,s.a)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"llama-open-and-efficient-foundation-language-models",children:"LLaMA: Open and Efficient Foundation Language Models"}),"\n",(0,t.jsx)(d.UW,{emoji:"⚠️",children:(0,t.jsx)(n.p,{children:"Esta secci\xf3n est\xe1 en pleno desarrollo."})}),"\n","\n",(0,t.jsx)(n.h2,{id:"qu\xe9-hay-de-nuevo",children:"\xbfQu\xe9 hay de nuevo?"}),"\n",(0,t.jsx)(n.p,{children:"Este paper presenta una colecci\xf3n de modelos de lenguaje fundamentales que van desde 7B hasta 65B de par\xe1metros."}),"\n",(0,t.jsx)(n.p,{children:"Los modelos est\xe1n entrenados con trillones de tokens con conjuntos de datos disponibles p\xfablicamente."}),"\n",(0,t.jsxs)(n.p,{children:["El trabajo de ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2203.15556",children:"(Hoffman et al. 2022)"})," muestra que, dado un presupuesto de computaci\xf3n, los modelos m\xe1s peque\xf1os entrenados con mucha m\xe1s datos pueden lograr un mejor rendimiento que los modelos m\xe1s grandes. Este trabajo recomienda entrenar modelos de 10B con 200B tokens. Sin embargo, el art\xedculo de LLaMA encuentra que el rendimiento de un modelo de 7B sigue mejorando incluso despu\xe9s de 1T de tokens."]}),"\n",(0,t.jsx)(l.w,{src:c.Z,alt:"LLAMA1"}),"\n",(0,t.jsx)(n.p,{children:"Este trabajo se centra en entrenar modelos (LLaMA) que logren el mejor rendimiento posible en varios presupuestos de inferencia, mediante el entrenamiento de m\xe1s tokens."}),"\n",(0,t.jsx)(n.h2,{id:"capacidades-y-resultados-clave",children:"Capacidades y resultados clave"}),"\n",(0,t.jsx)(n.p,{children:"En general, LLaMA-13B supera a GPT-3(175B) en muchos puntos de referencia a pesar de ser 10 veces m\xe1s peque\xf1o y posible de ejecutar en una sola GPU. LLaMA 65B es competitivo con modelos como Chinchilla-70B y PaLM-540B."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Paper:"})," ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2302.13971",children:"LLaMA: Open and Efficient Foundation Language Models"})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Code:"})," ",(0,t.jsx)(n.a,{href:"https://github.com/facebookresearch/llama",children:"https://github.com/facebookresearch/llama"})]}),"\n",(0,t.jsx)(n.h2,{id:"referencias",children:"Referencias"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://bair.berkeley.edu/blog/2023/04/03/koala/",children:"Koala: A Dialogue Model for Academic Research"})," (April 2023)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2304.01196",children:"Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data"})," (April 2023)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://vicuna.lmsys.org/",children:"Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality"})," (March 2023)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2303.16199",children:"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"})," (March 2023)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/nomic-ai/gpt4all",children:"GPT4All"})," (March 2023)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2303.14070",children:"ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge"})," (March 2023)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tatsu-lab/stanford_alpaca",children:"Stanford Alpaca"})," (March 2023)"]}),"\n"]})]})}let p={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,s.a)(),e.components);return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(x,{...e})}):x(e)},pageOpts:{filePath:"pages/models/llama.es.mdx",route:"/models/llama",timestamp:1681408895e3,pageMap:[{kind:"Meta",locale:"es",data:{index:"Ingenier\xeda de Prompt",introduction:"Introducci\xf3n",techniques:"T\xe9cnicas",applications:"Aplicaciones",models:"Modelos",risks:"Riesgos y Malos Usos",papers:"Papers",tools:"Herramientas",notebooks:"Notebooks",datasets:"Datasets",readings:"Lecturas Adicionales",course:{title:"Curso de Ingenier\xeda de Prompt",type:"page"},services:{title:"Servicios",type:"page"},about:{title:"Acerca de",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"es"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"es",data:{pal:"Modelos de lenguaje asistidos por programas",generating:"Generaci\xf3n de datos",coding:"Generating Code",workplace_casestudy:"Caso de estudio de clasificaci\xf3n de trabajo de graduados",pf:"Prompt Function"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"es"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"es"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"es"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"es"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"es"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"es"},{kind:"MdxPage",name:"course",route:"/course",locale:"es"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"es"},{kind:"MdxPage",name:"index",route:"/",locale:"es"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"es",data:{settings:"Configuraci\xf3n de LLM",basics:"Conceptos b\xe1sicos de prompting",elements:"Elementos de prompting",tips:"Consejos generales para dise\xf1ar prompts",examples:"Ejemplos de prompts"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"es"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"es"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"es"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"es"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"es"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"es"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"es",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"Listado de LLMs"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"es"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"es"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"es"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"es"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"es"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"es"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"es"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"es"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"es"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"es"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"es",data:{adversarial:"Adversarial Prompting",factuality:"Veracidad",biases:"Sesgos"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"es"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"es"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"es"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"es"},{kind:"MdxPage",name:"services",route:"/services",locale:"es"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"es",data:{zeroshot:"Prompt sin entrenamiento previo (Zero-shot)",fewshot:"Prompt con pocas muestras (Few-shot)",cot:"Prompt cadena de pensamiento (CoT)",consistency:"Auto-consistencia",knowledge:"Prompt de conocimiento generado",tot:"Tree of Thoughts",rag:"Retrieval Augmented Generation",art:"Automatic Reasoning and Tool-use",ape:"Ingenier\xeda de prompts autom\xe1tico (APE)",activeprompt:"Prompt activo",dsp:"Prompt de Est\xedmulo direccional",react:"ReAct",multimodalcot:"Prompt CoT multimodal",graph:"Prompt de grafo"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"es"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"es"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"es"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"es"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"es"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"es"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"es"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"es"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"es"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"es"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"es"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"es"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"es"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"es"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"es"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"es"}],flexsearch:{codeblocks:!0},title:"Llama",headings:u},pageNextRoute:"/models/llama.es",nextraLayout:i.ZP,themeConfig:r.Z};n.default=(0,o.j)(p)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=68657)}),_N_E=e.O()}]);