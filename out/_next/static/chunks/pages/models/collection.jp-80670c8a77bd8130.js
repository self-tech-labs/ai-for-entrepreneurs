(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[93695],{90595:function(e,r,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/models/collection.jp",function(){return t(23705)}])},43677:function(e,r,t){"use strict";t.d(r,{Z:function(){return g}});var n=t(11527),a=t(50959),i=t(85274),s=t(5341);function d(e){return(0,n.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,n.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:r,className:t,...a}=e;return(0,n.jsx)("button",{className:(0,s.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",t),...a,children:r})};function o(e){return(0,n.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function c(e){return(0,n.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,n.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,n.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let h=e=>{let{getValue:r,...t}=e,[i,s]=(0,a.useState)(!1);(0,a.useEffect)(()=>{if(!i)return;let e=setTimeout(()=>{s(!1)},2e3);return()=>{clearTimeout(e)}},[i]);let d=(0,a.useCallback)(async()=>{s(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(r())}catch(e){console.error("Failed to copy!")}},[r]);return(0,n.jsx)(l,{onClick:d,title:"Copy code",tabIndex:0,...t,children:(0,n.jsx)(i?o:c,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},x=e=>{let{children:r,className:t,hasCopyCode:i=!0,filename:o,...c}=e,x=(0,a.useRef)(null),j=(0,a.useCallback)(()=>{let e=document.documentElement.dataset,r="nextraWordWrap"in e;r?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,n.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[o&&(0,n.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:o}),(0,n.jsx)("pre",{className:(0,s.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",o?"nx-pt-12 nx-pb-4":"nx-py-4",t),ref:x,...c,children:a.isValidElement(r)&&"code"===r.type?r.props.children:r}),(0,n.jsxs)("div",{className:(0,s.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",o?"nx-top-8":"nx-top-0"),children:[(0,n.jsx)(l,{onClick:j,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,n.jsx)(d,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),i&&(0,n.jsx)(h,{getValue(){var e,r;return(null===(e=null===(r=x.current)||void 0===r?void 0:r.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},j={logo:(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,n.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,n.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,i.ZR)();return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,n.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,n.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,n.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,n.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:x}};var g=j},23705:function(e,r,t){"use strict";t.r(r),t.d(r,{__toc:function(){return o}});var n=t(11527),a=t(55411),i=t(85274),s=t(43677);t(20492),t(95178);var d=t(82132),l=t(63622);let o=[{depth:2,value:"Models",id:"models"}];function c(e){let r=Object.assign({h1:"h1",p:"p",a:"a",h2:"h2",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td"},(0,d.a)(),e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.h1,{children:"モデル一覧"}),"\n","\n",(0,n.jsx)(l.UW,{emoji:"⚠️",children:(0,n.jsx)(r.p,{children:"このセクションの内容は、鋭意開発進行中です。"})}),"\n",(0,n.jsxs)(r.p,{children:["このセクションには、注目すべきLLMの基礎技術(モデル)の一覧とその概要をまとめています(",(0,n.jsx)(r.a,{href:"https://paperswithcode.com/methods/category/language-models",children:"Papers with Code"}),"と",(0,n.jsx)(r.a,{href:"https://arxiv.org/pdf/2303.18223.pdf",children:"Zhao et al. (2023)"})," による直近の研究成果を元に一覧を作成しています)。"]}),"\n",(0,n.jsx)(r.h2,{id:"models",children:"Models"}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{children:"モデル名"}),(0,n.jsx)(r.th,{children:"発表された年"}),(0,n.jsx)(r.th,{children:"概要説明"})]})}),(0,n.jsxs)(r.tbody,{children:[(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1810.04805",children:"BERT"})}),(0,n.jsx)(r.td,{children:"2018"}),(0,n.jsx)(r.td,{children:"Transformer による双方向(Bidirectional)エンコーダーの特徴表現を利用したモデル"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf",children:"GPT"})}),(0,n.jsx)(r.td,{children:"2018"}),(0,n.jsx)(r.td,{children:"事前学習を利用した生成モデルにより、自然言語の理解を進展させた"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1907.11692",children:"RoBERTa"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"頑健性(Robustness)を重視して BERT を最適化する事前学習のアプローチ"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf",children:"GPT-2"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"自然言語モデルが、教師なし学習によってマルチタスクをこなせるようになるということを実証"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1910.10683",children:"T5"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"フォーマットを統一した Text-to-Text Transformer を用いて、転移学習の限界を探索"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1910.13461",children:"BART"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"自然言語の生成、翻訳、理解のために、 Sequence-to-Sequence な事前学習モデルのノイズを除去した"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1909.11942",children:"ALBERT"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"言語表現を自己教師学習するための BERT 軽量(Lite)化モデル"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1906.08237",children:"XLNet"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"自然言語の理解と生成のための自己回帰事前学習の一般化"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1909.05858",children:"CTRL"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"CTRL: 生成モデルをコントロール可能にするための、条件付き Transformer 言語モデル"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1904.09223v1",children:"ERNIE"})}),(0,n.jsx)(r.td,{children:"2019"}),(0,n.jsx)(r.td,{children:"ERNIE: 知識の統合を通じて特徴表現を高度化"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2006.16668v1",children:"GShard"})}),(0,n.jsx)(r.td,{children:"2020"}),(0,n.jsx)(r.td,{children:"GShard: 条件付き演算と自動シャーディング(Sharding)を用いた巨大モデルのスケーリング"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2005.14165",children:"GPT-3"})}),(0,n.jsx)(r.td,{children:"2020"}),(0,n.jsx)(r.td,{children:"自然言語モデルが、 Few-Shot で十分学習できるということを実証"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2201.08239v3",children:"LaMDA"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"LaMDA: 対話(Dialogue)アプリケーションのための自然言語モデル"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2104.12369v1",children:"PanGu-α"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"PanGu-α: 自動並列演算を用いて自己回帰事前学習された、中国語大規模言語モデル"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2010.11934v3",children:"mT5"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"mT5: 多言語で大規模に事前学習された text-to-text transformer"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2106.10715v3",children:"CPM-2"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"CPM-2: Large-scale Cost-effective Pre-trained Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.08207",children:"T0"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Multitask Prompted Training Enables Zero-Shot Task Generalization"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2109.04650",children:"HyperCLOVA"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2107.03374v2",children:"Codex"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Evaluating Large Language Models Trained on Code"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2107.02137v1",children:"ERNIE 3.0"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf",children:"Jurassic-1"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Jurassic-1: Technical Details and Evaluation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2109.01652v5",children:"FLAN"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Finetuned Language Models Are Zero-Shot Learners"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2201.11990v3",children:"MT-NLG"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.04725v2",children:"Yuan 1.0"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.09332v3",children:"WebGPT"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"WebGPT: Browser-assisted question-answering with human feedback"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.11446v2",children:"Gopher"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.12731v1",children:"ERNIE 3.0 Titan"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.06905",children:"GLaM"})}),(0,n.jsx)(r.td,{children:"2021"}),(0,n.jsx)(r.td,{children:"GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.02155v1",children:"InstructGPT"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Training language models to follow instructions with human feedback"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.06745v1",children:"GPT-NeoX-20B"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"GPT-NeoX-20B: An Open-Source Autoregressive Language Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.07814v1",children:"AlphaCode"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Competition-Level Code Generation with AlphaCode"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.13474v5",children:"CodeGen"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.15556",children:"Chinchilla"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Shows that for a compute budget, the best performances are not achieved by the largest models but by smaller models trained on more data."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.07705v3",children:"Tk-Instruct"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.05131v3",children:"UL2"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"UL2: Unifying Language Learning Paradigms"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.02311v5",children:"PaLM"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"PaLM: Scaling Language Modeling with Pathways"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.01068",children:"OPT"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"OPT: Open Pre-trained Transformer Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.05100v3",children:"BLOOM"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.02414v1",children:"GLM-130B"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"GLM-130B: An Open Bilingual Pre-trained Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2208.01448v2",children:"AlexaTM"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.11416v5",children:"Flan-T5"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Scaling Instruction-Finetuned Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2209.14375",children:"Sparrow"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Improving alignment of dialogue agents via targeted human judgements"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.11399v2",children:"U-PaLM"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Transcending Scaling Laws with 0.1% Extra Compute"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.01786v1",children:"mT0"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Crosslingual Generalization through Multitask Finetuning"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.09085v1",children:"Galactica"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"Galactica: A Large Language Model for Science"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.12017v3",children:"OPT-IML"})}),(0,n.jsx)(r.td,{children:"2022"}),(0,n.jsx)(r.td,{children:"OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.13971v1",children:"LLaMA"})}),(0,n.jsx)(r.td,{children:"2023"}),(0,n.jsx)(r.td,{children:"LLaMA: Open and Efficient Foundation Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.08774v3",children:"GPT-4"})}),(0,n.jsx)(r.td,{children:"2023"}),(0,n.jsx)(r.td,{children:"GPT-4 Technical Report"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.10845v1",children:"PanGu-Σ"})}),(0,n.jsx)(r.td,{children:"2023"}),(0,n.jsx)(r.td,{children:"PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17564v1",children:"BloombergGPT"})}),(0,n.jsx)(r.td,{children:"2023"}),(0,n.jsx)(r.td,{children:"BloombergGPT: A Large Language Model for Finance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://ai.google/static/documents/palm2techreport.pdf",children:"PaLM 2"})}),(0,n.jsx)(r.td,{children:"2023"}),(0,n.jsx)(r.td,{children:"A Language Model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM."})]})]})]})]})}let h={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:r}=Object.assign({},(0,d.a)(),e.components);return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(c,{...e})}):c(e)},pageOpts:{filePath:"pages/models/collection.jp.mdx",route:"/models/collection",timestamp:1684273448e3,pageMap:[{kind:"Meta",locale:"jp",data:{index:"Prompt Engineering",introduction:"Introduction",techniques:"Techniques",applications:"Applications",models:"Models",risks:"Risks & Misuses",papers:"Papers",tools:"Tools",notebooks:"Notebooks",datasets:"Datasets",readings:"Additional Readings",course:{title:"Prompt Engineering Course",type:"page"},services:{title:"Services",type:"page"},about:{title:"About",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"jp"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"jp",data:{pal:"PAL（プログラム支援言語モデル）",generating:"データ生成",coding:"Generating Code",workplace_casestudy:"Graduate Job Classification Case Study",pf:"Prompt Function"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"jp"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"jp"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"jp"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"jp"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"jp"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"jp"},{kind:"MdxPage",name:"course",route:"/course",locale:"jp"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"jp"},{kind:"MdxPage",name:"index",route:"/",locale:"jp"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"jp",data:{settings:"LLM設定",basics:"基本的なプロンプティング",elements:"プロンプトの要素",tips:"プロンプトをデザインする一般的なTips",examples:"プロンプトの例"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"jp"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"jp"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"jp"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"jp"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"jp"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"jp"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"jp",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"Model Collection"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"jp"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"jp"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"jp"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"jp"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"jp"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"jp"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"jp"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"jp"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"jp"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"jp"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"jp",data:{adversarial:"敵対的Prompting",factuality:"事実性",biases:"バイアス"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"jp"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"jp"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"jp"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"jp"},{kind:"MdxPage",name:"services",route:"/services",locale:"jp"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"jp",data:{zeroshot:"Zero-shotプロンプティング",fewshot:"Few-shotプロンプティング",cot:"Chain-of-Thoughtプロンプティング",consistency:"自己整合性（Self-Consistency）",knowledge:"知識生成プロンプティング",tot:"Tree of Thoughts",rag:"Retrieval Augmented Generation",art:"Automatic Reasoning and Tool-use",ape:"自動プロンプトエンジニア",activeprompt:"アクティブプロンプト",dsp:"方向性刺激プロンプティング",react:"ReAct",multimodalcot:"マルチモーダルCoT",graph:"グラフプロンプト（GraphPrompts）"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"jp"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"jp"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"jp"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"jp"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"jp"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"jp"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"jp"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"jp"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"jp"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"jp"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"jp"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"jp"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"jp"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"jp"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"jp"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"jp"}],flexsearch:{codeblocks:!0},title:"モデル一覧",headings:o},pageNextRoute:"/models/collection.jp",nextraLayout:i.ZP,themeConfig:s.Z};r.default=(0,a.j)(h)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=90595)}),_N_E=e.O()}]);