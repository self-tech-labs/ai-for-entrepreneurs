(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[14095],{72030:function(e,a,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/models/flan.es",function(){return n(70363)}])},30339:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-1.c26df985.png",height:507,width:940,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAaUlEQVR42g3MSQqAIBQAUO9/p1YRtGqyAovUskGk32DYgIG1e6uHdnNndMRcLto45zbznPb9gVQ3RV5YBqkcJvtaguvCj1chESjVVmSgfAGYAUbBSRILRtFx6bLPix4ft/4HJpuURVTVH/oBVkaCL0fpAAAAAElFTkSuQmCC",blurWidth:8,blurHeight:4}},40941:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-10.60080e50.png",height:660,width:955,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAIAAABxZ0isAAAAgUlEQVR42gUA2Q6CMGztto5dkuiLif//ayoJBAsjHDtiYBjnKzcB4DvKJZ+5AYA1Ws0pDcy2c/falat+mJ11vSVY0vRLIwhhjPcU93MFAESlOMnangIwSJqWdTsIEZ01ajv4yxORqS2sSbznLcbgc1F9wKNciFkq/XrEm921LkqKPz+jP3C12xf+AAAAAElFTkSuQmCC",blurWidth:8,blurHeight:6}},53094:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-11.3b3298da.png",height:708,width:978,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAIAAABxZ0isAAAAhUlEQVR42gVA3QqCMBR2Z9/+LKGLLqqLoPd/qSAoaDoLddqZbiF8/555ImqGKZVSmp3j3+iMxTM8Yg5iu/VfA0Uujm13v54vsLrmtJplzWOWEFaA90cNI3wb2hCUBKCllFCiEmSNhkU6HYik5BirUpBdWnhjoLAn9lBNGmatiT9meHWi1n9VMUQoSvzVuwAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:6}},95082:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-2.10409595.png",height:376,width:867,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAADCAIAAAAhqtkfAAAAO0lEQVR42hWLQQ4AIQjE/P9zXaIdhpDFQ3tql0R3Q9stKV0D8tp7Q48yFRFOvyS9qgqI+O69swrOOcAPRnlGBl0y3MIAAAAASUVORK5CYII=",blurWidth:8,blurHeight:3}},35999:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-3.db3a0ec9.png",height:500,width:811,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAVUlEQVR42h2MSRIAIQwC8//fumQT1InTB4oDtACICFVdmSS9iDB3MbMN+lTyLUCmB9eSMYargrj31i/ND16XLFYCIFlZQvzIOWdO7b2XfAN1aq1FxAd+RXSe+SxRUAAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:5}},81646:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-4.a595d5a6.png",height:377,width:814,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAMAAACEE47CAAAAM1BMVEX9/f37+/v6+vr5+vn5+fn4+Pj39/f29vb09fT09PTz8/Py8vLx8fHv8O/u7u7p6eno6OiBxzfzAAAAJ0lEQVR42gVAARIAEAhbMxSF/7/WYZKZVQv7mJpMiNcpgogbHkP+ARBFAN4Pn1uoAAAAAElFTkSuQmCC",blurWidth:8,blurHeight:4}},77883:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-5.98a6c013.png",height:604,width:954,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAYklEQVR42gUACQ7CIIz/P1McMmrtxboFKDEJyUpjNcf8uhDNpH4/YpwAKR8nscJxcAMRrlBZKBGRqrp7J3rcxxgRsdZKDSgXUL3gnX+1WteGp3ZJZtq7PffdShGROefeOyL+W19wuygsro4AAAAASUVORK5CYII=",blurWidth:8,blurHeight:5}},83974:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-6.a24343d8.png",height:538,width:599,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAIAAAC6O5sJAAAAj0lEQVR42k2Myw6DIBRE+f+f6r514ao1Nk2aYnyAgICXlwK1dONZzGJOZlBKKecslSaEcM6dc6mA/kJITenMGFsWmWI8mp+w1uYTiwJjPfLeA0Auu46IFez1jsdZIjDGOTsxNQtVP4duZFWDCVfIhxC3UD1w+x7qtnt9+sutoUKj4yHu+0S5Xk1JwP3ow/YF6yiesVw+ygoAAAAASUVORK5CYII=",blurWidth:8,blurHeight:7}},9569:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-7.c600a1de.png",height:446,width:947,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAVklEQVR42g3HWw6DMAwEwNz/nCARpS1xsuuHKA7M35Szo/0wBj/7Lq1RIejqLFQHg6AcB7uYKY0eXmSwD51g3bZvrcCETg8rmbnWCrd59lC9rv/bvPMBwR5bkGNNX9AAAAAASUVORK5CYII=",blurWidth:8,blurHeight:4}},68376:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-8.fda963af.png",height:593,width:935,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAe0lEQVR42iXM0QqCMBSA4b3/G0VQEdTFQAdZtLWpa1vHHY+d0uo+Qfhv/080iVzoXRx6/iJx7Kij1/j5CWUum/KwP0kd6pjTulgpX9isRQtG6p00W/s480SqOV6hbMmITAz4XHbiEYf33DRTN+8rZ22KQOhCqGprwh0I/5rQaVAcbK0sAAAAAElFTkSuQmCC",blurWidth:8,blurHeight:5}},43981:function(e,a){"use strict";a.Z={src:"/_next/static/media/flan-9.78364907.png",height:521,width:942,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAYUlEQVR42g3GWw6DIBAAQO5/tzaNaWtSEMTuwj5EWb2Azte4BOQzRhTdLRcOS73f+uG0KRDyJv3ouq0ohRrbae6b6OXp6amohb8Mob4jg5gb0/T4fYbZZ4Kl1nGeYgFUvgDav1WzCaT5agAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:4}},41667:function(e,a,n){"use strict";n.d(a,{w:function(){return r}});var t=n(11527),i=n(5341),s=n(76484),o=n.n(s);function r(e){let{src:a,alt:n,full:s}=e;return(0,t.jsx)("div",{className:(0,i.Z)("mt-6 -mb-4 flex justify-center overflow-hidden rounded-xl border dark:border-zinc-800",s?"bg-white":"bg-zinc-100"),children:(0,t.jsx)(o(),{src:a,alt:n,className:(0,i.Z)("w-auto select-none bg-white",s?"":"ring-1 ring-gray-200")})})}},43677:function(e,a,n){"use strict";n.d(a,{Z:function(){return A}});var t=n(11527),i=n(50959),s=n(85274),o=n(5341);function r(e){return(0,t.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,t.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:a,className:n,...i}=e;return(0,t.jsx)("button",{className:(0,o.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",n),...i,children:a})};function d(e){return(0,t.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,t.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function c(e){return(0,t.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,t.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,t.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let u=e=>{let{getValue:a,...n}=e,[s,o]=(0,i.useState)(!1);(0,i.useEffect)(()=>{if(!s)return;let e=setTimeout(()=>{o(!1)},2e3);return()=>{clearTimeout(e)}},[s]);let r=(0,i.useCallback)(async()=>{o(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(a())}catch(e){console.error("Failed to copy!")}},[a]);return(0,t.jsx)(l,{onClick:r,title:"Copy code",tabIndex:0,...n,children:(0,t.jsx)(s?d:c,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},g=e=>{let{children:a,className:n,hasCopyCode:s=!0,filename:d,...c}=e,g=(0,i.useRef)(null),x=(0,i.useCallback)(()=>{let e=document.documentElement.dataset,a="nextraWordWrap"in e;a?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,t.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[d&&(0,t.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:d}),(0,t.jsx)("pre",{className:(0,o.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",d?"nx-pt-12 nx-pb-4":"nx-py-4",n),ref:g,...c,children:i.isValidElement(a)&&"code"===a.type?a.props.children:a}),(0,t.jsxs)("div",{className:(0,o.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",d?"nx-top-8":"nx-top-0"),children:[(0,t.jsx)(l,{onClick:x,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,t.jsx)(r,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),s&&(0,t.jsx)(u,{getValue(){var e,a;return(null===(e=null===(a=g.current)||void 0===a?void 0:a.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},x={logo:(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,t.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,t.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,t.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,t.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,s.ZR)();return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,t.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,t.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,t.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,t.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,t.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,t.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:g}};var A=x},70363:function(e,a,n){"use strict";n.r(a),n.d(a,{__toc:function(){return j}});var t=n(11527),i=n(55411),s=n(85274),o=n(43677);n(20492),n(95178);var r=n(82132),l=n(41667),d=n(30339),c=n(95082),u=n(35999),g=n(81646),x=n(77883),A=n(83974),m=n(9569),p=n(68376),h=n(43981),f=n(40941),b=n(53094);let j=[{depth:2,value:"\xbfQu\xe9 hay de nuevo?",id:"qu\xe9-hay-de-nuevo"},{depth:2,value:"Capacidades y resultados clave",id:"capacidades-y-resultados-clave"}];function k(e){let a=Object.assign({h1:"h1",h2:"h2",p:"p",a:"a",strong:"strong",ul:"ul",li:"li"},(0,r.a)(),e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.h1,{children:"Scaling Instruction-Finetuned Language Models"}),"\n","\n",(0,t.jsx)(a.h2,{id:"qu\xe9-hay-de-nuevo",children:"\xbfQu\xe9 hay de nuevo?"}),"\n",(0,t.jsx)(l.w,{src:d.Z,alt:"FLAN1"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsxs)(a.p,{children:["Este documento explora los beneficios del escalado del ajuste de instrucciones (",(0,t.jsx)(a.a,{href:"https://arxiv.org/pdf/2109.01652.pdf",children:"instruction finetuning"}),") y c\xf3mo mejora el rendimiento en una variedad de modelos (PaLM, T5), configuraciones de prompts (zero-shot, few-shot, CoT) y referencias (MMLU, TyDiQA). Esto se explora con los siguientes aspectos: escalar el n\xfamero de tareas (1,8K tareas), escalar el tama\xf1o del modelo y ajustar los datos en la cadena de pensamiento (se usaron 9 conjuntos de datos)."]}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.strong,{children:"Procedimiento de finetuning:"})}),"\n",(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsx)(a.li,{children:"1.8K tareas se formularon como instrucciones y se usaron para ajustar el modelo"}),"\n",(0,t.jsx)(a.li,{children:"Se utilizan tanto con como sin ejemplos, y con y sin CoT"}),"\n"]}),"\n",(0,t.jsx)(a.p,{children:"Se muestran las tareas de finetuning y las tareas retenidas a continuaci\xf3n:"}),"\n",(0,t.jsx)(l.w,{src:b.Z,alt:"FLAN11"}),"\n",(0,t.jsx)(a.h2,{id:"capacidades-y-resultados-clave",children:"Capacidades y resultados clave"}),"\n",(0,t.jsxs)(a.ul,{children:["\n",(0,t.jsx)(a.li,{children:"El ajuste de instrucciones escala bien con el n\xfamero de tareas y el tama\xf1o del modelo; esto sugiere la necesidad de escalar el n\xfamero de tareas y el tama\xf1o del modelo a\xfan m\xe1s"}),"\n",(0,t.jsx)(a.li,{children:"Agregar conjuntos de datos CoT en el finetuning permite un buen rendimiento en tareas de razonamiento"}),"\n",(0,t.jsx)(a.li,{children:"Flan-PaLM tiene mejores habilidades multiling\xfces; mejora del 14.9% en TyDiQA de una sola pasada; mejora del 8.1% en razonamiento aritm\xe9tico en idiomas subrepresentados"}),"\n",(0,t.jsx)(a.li,{children:"Plan-PaLM tambi\xe9n tiene un buen rendimiento en preguntas de generaci\xf3n abierta, lo que es un buen indicador de una mejor usabilidad"}),"\n",(0,t.jsx)(a.li,{children:"Mejora el rendimiento en referencias de IA responsable (RAI)"}),"\n",(0,t.jsx)(a.li,{children:"Los modelos de ajuste de instrucciones de Flan-T5 demuestran fuertes capacidades de few-shot y superan a los puntos de control p\xfablicos como T5"}),"\n"]}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Los resultados al escalar el n\xfamero de tareas de ajuste y el tama\xf1o del modelo:"})," se espera que la escalabilidad tanto del tama\xf1o del modelo como del n\xfamero de tareas de ajuste contin\xfae mejorando el rendimiento, aunque la escalabilidad del n\xfamero de tareas tiene retornos disminuidos."]}),"\n",(0,t.jsx)(l.w,{src:c.Z,alt:"FLAN2"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Resultados al ajustar con datos no-CoT y CoT:"})," El ajuste conjunto con datos no-CoT y CoT mejora el rendimiento en ambas evaluaciones, en comparaci\xf3n con el ajuste en solo uno u otro."]}),"\n",(0,t.jsx)(l.w,{src:u.Z,alt:"FLAN3"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(a.p,{children:"Adem\xe1s, la autoconsistencia combinada con CoT logra resultados de estado del arte en varios benchmarks. CoT + autoconsistencia tambi\xe9n mejora significativamente los resultados en benchmarks que involucran problemas matem\xe1ticos (por ejemplo, MGSM, GSM8K)."}),"\n",(0,t.jsx)(l.w,{src:g.Z,alt:"FLAN4"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(a.p,{children:'El ajuste de CoT desbloquea el razonamiento sin ayuda (zero-shot), activado por la frase "pensemos paso a paso", en tareas de BIG-Bench. En general, Flan-PaLM CoT sin ayuda supera en rendimiento a PaLM CoT sin ajuste.'}),"\n",(0,t.jsx)(l.w,{src:A.Z,alt:"FLAN6"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(a.p,{children:"A continuaci\xf3n se presentan algunas demostraciones de CoT sin ayuda para PaLM y Flan-PaLM en tareas no vistas."}),"\n",(0,t.jsx)(l.w,{src:x.Z,alt:"FLAN5"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(a.p,{children:"A continuaci\xf3n se presentan m\xe1s ejemplos de prompts zero-shot. Muestra c\xf3mo el modelo PaLM tiene dificultades con las repeticiones y no responde a las instrucciones en el ajuste sin ayuda, mientras que Flan-PaLM puede desempe\xf1arse bien. Los ejemplos con pocos ejemplos pueden mitigar estos errores."}),"\n",(0,t.jsx)(l.w,{src:m.Z,alt:"FLAN7"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(a.p,{children:"A continuaci\xf3n se presentan algunos ejemplos que demuestran las capacidades sin ayuda (zero-shot) del modelo Flan-PaLM en varios tipos diferentes de preguntas abiertas complejas:"}),"\n",(0,t.jsx)(l.w,{src:p.Z,alt:"FLAN8"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(l.w,{src:h.Z,alt:"FLAN9"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsx)(l.w,{src:f.Z,alt:"FLAN10"}),"\n",(0,t.jsxs)(a.p,{children:["Fuente de la imagen: ",(0,t.jsx)(a.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,t.jsxs)(a.p,{children:["Puedes probar ",(0,t.jsx)(a.a,{href:"https://huggingface.co/google/flan-t5-xxl",children:"los modelos Flan-T5 en el Hugging Face Hub"}),"."]})]})}let v={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:a}=Object.assign({},(0,r.a)(),e.components);return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(k,{...e})}):k(e)},pageOpts:{filePath:"pages/models/flan.es.mdx",route:"/models/flan",timestamp:168146713e4,pageMap:[{kind:"Meta",locale:"es",data:{index:"Ingenier\xeda de Prompt",introduction:"Introducci\xf3n",techniques:"T\xe9cnicas",applications:"Aplicaciones",models:"Modelos",risks:"Riesgos y Malos Usos",papers:"Papers",tools:"Herramientas",notebooks:"Notebooks",datasets:"Datasets",readings:"Lecturas Adicionales",course:{title:"Curso de Ingenier\xeda de Prompt",type:"page"},services:{title:"Servicios",type:"page"},about:{title:"Acerca de",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"es"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"es",data:{pal:"Modelos de lenguaje asistidos por programas",generating:"Generaci\xf3n de datos",coding:"Generating Code",workplace_casestudy:"Caso de estudio de clasificaci\xf3n de trabajo de graduados",pf:"Prompt Function"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"es"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"es"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"es"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"es"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"es"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"es"},{kind:"MdxPage",name:"course",route:"/course",locale:"es"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"es"},{kind:"MdxPage",name:"index",route:"/",locale:"es"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"es",data:{settings:"Configuraci\xf3n de LLM",basics:"Conceptos b\xe1sicos de prompting",elements:"Elementos de prompting",tips:"Consejos generales para dise\xf1ar prompts",examples:"Ejemplos de prompts"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"es"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"es"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"es"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"es"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"es"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"es"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"es",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"Listado de LLMs"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"es"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"es"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"es"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"es"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"es"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"es"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"es"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"es"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"es"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"es"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"es",data:{adversarial:"Adversarial Prompting",factuality:"Veracidad",biases:"Sesgos"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"es"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"es"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"es"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"es"},{kind:"MdxPage",name:"services",route:"/services",locale:"es"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"es",data:{zeroshot:"Prompt sin entrenamiento previo (Zero-shot)",fewshot:"Prompt con pocas muestras (Few-shot)",cot:"Prompt cadena de pensamiento (CoT)",consistency:"Auto-consistencia",knowledge:"Prompt de conocimiento generado",tot:"Tree of Thoughts",rag:"Retrieval Augmented Generation",art:"Automatic Reasoning and Tool-use",ape:"Ingenier\xeda de prompts autom\xe1tico (APE)",activeprompt:"Prompt activo",dsp:"Prompt de Est\xedmulo direccional",react:"ReAct",multimodalcot:"Prompt CoT multimodal",graph:"Prompt de grafo"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"es"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"es"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"es"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"es"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"es"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"es"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"es"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"es"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"es"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"es"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"es"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"es"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"es"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"es"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"es"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"es"}],flexsearch:{codeblocks:!0},title:"Scaling Instruction-Finetuned Language Models",headings:j},pageNextRoute:"/models/flan.es",nextraLayout:s.ZP,themeConfig:o.Z};a.default=(0,i.j)(v)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=72030)}),_N_E=e.O()}]);