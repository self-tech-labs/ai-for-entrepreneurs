(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[36393],{48561:function(e,r,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/models/collection.tr",function(){return t(93860)}])},43677:function(e,r,t){"use strict";t.d(r,{Z:function(){return g}});var n=t(11527),i=t(50959),d=t(85274),s=t(5341);function a(e){return(0,n.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,n.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:r,className:t,...i}=e;return(0,n.jsx)("button",{className:(0,s.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",t),...i,children:r})};function c(e){return(0,n.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function h(e){return(0,n.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,n.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,n.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let o=e=>{let{getValue:r,...t}=e,[d,s]=(0,i.useState)(!1);(0,i.useEffect)(()=>{if(!d)return;let e=setTimeout(()=>{s(!1)},2e3);return()=>{clearTimeout(e)}},[d]);let a=(0,i.useCallback)(async()=>{s(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(r())}catch(e){console.error("Failed to copy!")}},[r]);return(0,n.jsx)(l,{onClick:a,title:"Copy code",tabIndex:0,...t,children:(0,n.jsx)(d?c:h,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},x=e=>{let{children:r,className:t,hasCopyCode:d=!0,filename:c,...h}=e,x=(0,i.useRef)(null),j=(0,i.useCallback)(()=>{let e=document.documentElement.dataset,r="nextraWordWrap"in e;r?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,n.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[c&&(0,n.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:c}),(0,n.jsx)("pre",{className:(0,s.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",c?"nx-pt-12 nx-pb-4":"nx-py-4",t),ref:x,...h,children:i.isValidElement(r)&&"code"===r.type?r.props.children:r}),(0,n.jsxs)("div",{className:(0,s.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",c?"nx-top-8":"nx-top-0"),children:[(0,n.jsx)(l,{onClick:j,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,n.jsx)(a,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),d&&(0,n.jsx)(o,{getValue(){var e,r;return(null===(e=null===(r=x.current)||void 0===r?void 0:r.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},j={logo:(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,n.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,n.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,d.ZR)();return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,n.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,n.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,n.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,n.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:x}};var g=j},93860:function(e,r,t){"use strict";t.r(r),t.d(r,{__toc:function(){return c}});var n=t(11527),i=t(55411),d=t(85274),s=t(43677);t(20492),t(95178);var a=t(82132),l=t(63622);let c=[{depth:2,value:"Models",id:"models"}];function h(e){let r=Object.assign({h1:"h1",p:"p",h2:"h2",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td",a:"a"},(0,a.a)(),e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.h1,{children:"LLM Koleksiyonu"}),"\n","\n",(0,n.jsx)(r.p,{children:"Bu b\xf6l\xfcm, dikkate değer ve temel LLM'lerin bir koleksiyonunu ve \xf6zetini i\xe7erir."}),"\n",(0,n.jsx)(r.h2,{id:"models",children:"Models"}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{children:"Model"}),(0,n.jsx)(r.th,{children:"\xc7ıkış Tarihi"}),(0,n.jsx)(r.th,{children:"Boyut (B)"}),(0,n.jsx)(r.th,{children:"Kontrol Noktaları"}),(0,n.jsx)(r.th,{children:"A\xe7ıklama"})]})}),(0,n.jsxs)(r.tbody,{children:[(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://falconllm.tii.ae/",children:"Falcon LLM"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"7, 40"}),(0,n.jsxs)(r.td,{children:[(0,n.jsx)(r.a,{href:"https://huggingface.co/tiiuae",children:"Falcon-7B"}),", ",(0,n.jsx)(r.a,{href:"https://huggingface.co/tiiuae/falcon-40b",children:"Falcon-40B"})]}),(0,n.jsx)(r.td,{children:"Falcon LLM is a foundational large language model (LLM) with 40 billion parameters trained on one trillion tokens. TII has now released Falcon LLM – a 40B model."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.10403",children:"PaLM 2"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"A Language Model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.09617v1",children:"Med-PaLM 2"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Towards Expert-Level Medical Question Answering with Large Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.15334v1",children:"Gorilla"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"7"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/ShishirPatil/gorilla",children:"Gorilla"})}),(0,n.jsx)(r.td,{children:"Gorilla: Large Language Model Connected with Massive APIs"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://www.together.xyz/blog/redpajama-models-v1",children:"RedPajama-INCITE"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"3, 7"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/togethercomputer",children:"RedPajama-INCITE"})}),(0,n.jsx)(r.td,{children:"A family of models including base, instruction-tuned & chat models."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.11206v1",children:"LIMA"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"65"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"A 65B parameter LLaMa language model fine-tuned with the standard supervised loss on only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/replit",children:"Replit Code"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"3"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/replit",children:"Replit Code"})}),(0,n.jsx)(r.td,{children:"replit-code-v1-3b model is a 2.7B LLM trained on 20 languages from the Stack Dedup v1.2 dataset."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/h2oai/h2ogpt",children:"h2oGPT"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"12"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/h2oai/h2ogpt",children:"h2oGPT"})}),(0,n.jsx)(r.td,{children:"h2oGPT is a large language model (LLM) fine-tuning framework and chatbot UI with document(s) question-answer capabilities."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.02309",children:"CodeGen2"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"1, 3, 7, 16"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/salesforce/codegen2",children:"CodeGen2"})}),(0,n.jsx)(r.td,{children:"Code models for program synthesis."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2305.07922",children:"CodeT5 and CodeT5+"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"16"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/salesforce/codet5",children:"CodeT5"})}),(0,n.jsx)(r.td,{children:"CodeT5 and CodeT5+ models for Code Understanding and Generation from Salesforce Research."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/blog/starcoder",children:"StarCoder"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"15"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/bigcode/starcoder",children:"StarCoder"})}),(0,n.jsx)(r.td,{children:"StarCoder: A State-of-the-Art LLM for Code"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://www.mosaicml.com/blog/mpt-7b",children:"MPT-7B"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"7"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/mosaicml/llm-foundry#mpt",children:"MPT-7B"})}),(0,n.jsx)(r.td,{children:"MPT-7B is a GPT-style model, and the first in the MosaicML Foundation Series of models."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://medium.com/ai-squared/announcing-dlite-v2-lightweight-open-llms-that-can-run-anywhere-a852e5978c6e",children:"DLite"})}),(0,n.jsx)(r.td,{children:"May 2023"}),(0,n.jsx)(r.td,{children:"0.124 - 1.5"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/aisquared/dlite-v2-1_5b",children:"DLite-v2-1.5B"})}),(0,n.jsx)(r.td,{children:"Lightweight instruction following models which exhibit ChatGPT-like interactivity."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm",children:"Dolly"})}),(0,n.jsx)(r.td,{children:"April 2023"}),(0,n.jsx)(r.td,{children:"3, 7, 12"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/databricks/dolly-v2-12b",children:"Dolly"})}),(0,n.jsx)(r.td,{children:"An instruction-following LLM, fine-tuned on a human-generated instruction dataset licensed for research and commercial use."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/Stability-AI/StableLM#stablelm-alpha",children:"StableLM"})}),(0,n.jsx)(r.td,{children:"April 2023"}),(0,n.jsx)(r.td,{children:"3, 7"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/Stability-AI/StableLM#stablelm-alpha",children:"StableLM-Alpha"})}),(0,n.jsx)(r.td,{children:"Stability AI's StableLM series of language models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.01373",children:"Pythia"})}),(0,n.jsx)(r.td,{children:"April 2023"}),(0,n.jsx)(r.td,{children:"0.070 - 12"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/eleutherai/pythia",children:"Pythia"})}),(0,n.jsx)(r.td,{children:"A suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://open-assistant.io/",children:"Open Assistant (Pythia Family)"})}),(0,n.jsx)(r.td,{children:"March 2023"}),(0,n.jsx)(r.td,{children:"12"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/OpenAssistant",children:"Open Assistant"})}),(0,n.jsx)(r.td,{children:"OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2304.03208",children:"Cerebras-GPT"})}),(0,n.jsx)(r.td,{children:"March 2023"}),(0,n.jsx)(r.td,{children:"0.111 - 13"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/cerebras",children:"Cerebras-GPT"})}),(0,n.jsx)(r.td,{children:"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17564v1",children:"BloombergGPT"})}),(0,n.jsx)(r.td,{children:"March 2023"}),(0,n.jsx)(r.td,{children:"50"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"BloombergGPT: A Large Language Model for Finance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.10845v1",children:"PanGu-Σ"})}),(0,n.jsx)(r.td,{children:"March 2023"}),(0,n.jsx)(r.td,{children:"1085"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2303.08774v3",children:"GPT-4"})}),(0,n.jsx)(r.td,{children:"March 2023"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"GPT-4 Technical Report"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2302.13971v1",children:"LLaMA"})}),(0,n.jsx)(r.td,{children:"Feb 2023"}),(0,n.jsx)(r.td,{children:"7, 13, 33, 65"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/facebookresearch/llama",children:"LLaMA"})}),(0,n.jsx)(r.td,{children:"LLaMA: Open and Efficient Foundation Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://openai.com/blog/chatgpt",children:"ChatGPT"})}),(0,n.jsx)(r.td,{children:"Nov 2022"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"A model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.09085v1",children:"Galactica"})}),(0,n.jsx)(r.td,{children:"Nov 2022"}),(0,n.jsx)(r.td,{children:"0.125 - 120"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/models?other=galactica",children:"Galactica"})}),(0,n.jsx)(r.td,{children:"Galactica: A Large Language Model for Science"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.01786v1",children:"mT0"})}),(0,n.jsx)(r.td,{children:"Nov 2022"}),(0,n.jsx)(r.td,{children:"13"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/bigscience/mt0-xxl",children:"mT0-xxl"})}),(0,n.jsx)(r.td,{children:"Crosslingual Generalization through Multitask Finetuning"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2211.05100v3",children:"BLOOM"})}),(0,n.jsx)(r.td,{children:"Nov 2022"}),(0,n.jsx)(r.td,{children:"176"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/bigscience/bloom",children:"BLOOM"})}),(0,n.jsx)(r.td,{children:"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.11399v2",children:"U-PaLM"})}),(0,n.jsx)(r.td,{children:"Oct 2022"}),(0,n.jsx)(r.td,{children:"540"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Transcending Scaling Laws with 0.1% Extra Compute"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.05131v3",children:"UL2"})}),(0,n.jsx)(r.td,{children:"Oct 2022"}),(0,n.jsx)(r.td,{children:"20"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/google-research/google-research/tree/master/ul2#checkpoints",children:"UL2, Flan-UL2"})}),(0,n.jsx)(r.td,{children:"UL2: Unifying Language Learning Paradigms"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2209.14375",children:"Sparrow"})}),(0,n.jsx)(r.td,{children:"Sep 2022"}),(0,n.jsx)(r.td,{children:"70"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Improving alignment of dialogue agents via targeted human judgements"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.11416v5",children:"Flan-T5"})}),(0,n.jsx)(r.td,{children:"Oct 2022"}),(0,n.jsx)(r.td,{children:"11"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/google/flan-t5-xxl",children:"Flan-T5-xxl"})}),(0,n.jsx)(r.td,{children:"Scaling Instruction-Finetuned Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2208.01448v2",children:"AlexaTM"})}),(0,n.jsx)(r.td,{children:"Aug 2022"}),(0,n.jsx)(r.td,{children:"20"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2210.02414v1",children:"GLM-130B"})}),(0,n.jsx)(r.td,{children:"Oct 2022"}),(0,n.jsx)(r.td,{children:"130"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/THUDM/GLM-130B",children:"GLM-130B"})}),(0,n.jsx)(r.td,{children:"GLM-130B: An Open Bilingual Pre-trained Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2212.12017v3",children:"OPT-IML"})}),(0,n.jsx)(r.td,{children:"Dec 2022"}),(0,n.jsx)(r.td,{children:"30, 175"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/facebookresearch/metaseq/tree/main/projects/OPT-IML#pretrained-model-weights",children:"OPT-IML"})}),(0,n.jsx)(r.td,{children:"OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2205.01068",children:"OPT"})}),(0,n.jsx)(r.td,{children:"May 2022"}),(0,n.jsx)(r.td,{children:"175"}),(0,n.jsxs)(r.td,{children:[(0,n.jsx)(r.a,{href:"https://huggingface.co/facebook/opt-13b",children:"OPT-13B"}),", ",(0,n.jsx)(r.a,{href:"https://huggingface.co/facebook/opt-66b",children:"OPT-66B"})]}),(0,n.jsx)(r.td,{children:"OPT: Open Pre-trained Transformer Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.02311v5",children:"PaLM"})}),(0,n.jsx)(r.td,{children:"April 2022"}),(0,n.jsx)(r.td,{children:"540"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"PaLM: Scaling Language Modeling with Pathways"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.07705v3",children:"Tk-Instruct"})}),(0,n.jsx)(r.td,{children:"April 2022"}),(0,n.jsx)(r.td,{children:"11"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/allenai/tk-instruct-11b-def",children:"Tk-Instruct-11B"})}),(0,n.jsx)(r.td,{children:"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2204.06745v1",children:"GPT-NeoX-20B"})}),(0,n.jsx)(r.td,{children:"April 2022"}),(0,n.jsx)(r.td,{children:"20"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/EleutherAI/gpt-neox-20b",children:"GPT-NeoX-20B"})}),(0,n.jsx)(r.td,{children:"GPT-NeoX-20B: An Open-Source Autoregressive Language Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.15556",children:"Chinchilla"})}),(0,n.jsx)(r.td,{children:"Mar 2022"}),(0,n.jsx)(r.td,{children:"70"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Shows that for a compute budget, the best performances are not achieved by the largest models but by smaller models trained on more data."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.02155v1",children:"InstructGPT"})}),(0,n.jsx)(r.td,{children:"Mar 2022"}),(0,n.jsx)(r.td,{children:"175"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Training language models to follow instructions with human feedback"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.13474v5",children:"CodeGen"})}),(0,n.jsx)(r.td,{children:"Mar 2022"}),(0,n.jsx)(r.td,{children:"0.350 - 16"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/models?search=salesforce+codegen",children:"CodeGen"})}),(0,n.jsx)(r.td,{children:"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2203.07814v1",children:"AlphaCode"})}),(0,n.jsx)(r.td,{children:"Feb 2022"}),(0,n.jsx)(r.td,{children:"41"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Competition-Level Code Generation with AlphaCode"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2201.11990v3",children:"MT-NLG"})}),(0,n.jsx)(r.td,{children:"Jan 2022"}),(0,n.jsx)(r.td,{children:"530"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2201.08239v3",children:"LaMDA"})}),(0,n.jsx)(r.td,{children:"Jan 2022"}),(0,n.jsx)(r.td,{children:"137"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"LaMDA: Language Models for Dialog Applications"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.06905",children:"GLaM"})}),(0,n.jsx)(r.td,{children:"Dec 2021"}),(0,n.jsx)(r.td,{children:"1200"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.11446v2",children:"Gopher"})}),(0,n.jsx)(r.td,{children:"Dec 2021"}),(0,n.jsx)(r.td,{children:"280"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.09332v3",children:"WebGPT"})}),(0,n.jsx)(r.td,{children:"Dec 2021"}),(0,n.jsx)(r.td,{children:"175"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"WebGPT: Browser-assisted question-answering with human feedback"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.04725v2",children:"Yuan 1.0"})}),(0,n.jsx)(r.td,{children:"Oct 2021"}),(0,n.jsx)(r.td,{children:"245"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2110.08207",children:"T0"})}),(0,n.jsx)(r.td,{children:"Oct 2021"}),(0,n.jsx)(r.td,{children:"11"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://huggingface.co/bigscience/T0",children:"T0"})}),(0,n.jsx)(r.td,{children:"Multitask Prompted Training Enables Zero-Shot Task Generalization"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2109.01652v5",children:"FLAN"})}),(0,n.jsx)(r.td,{children:"Sep 2021"}),(0,n.jsx)(r.td,{children:"137"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Finetuned Language Models Are Zero-Shot Learners"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2109.04650",children:"HyperCLOVA"})}),(0,n.jsx)(r.td,{children:"Sep 2021"}),(0,n.jsx)(r.td,{children:"82"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2112.12731v1",children:"ERNIE 3.0 Titan"})}),(0,n.jsx)(r.td,{children:"July 2021"}),(0,n.jsx)(r.td,{children:"10"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf",children:"Jurassic-1"})}),(0,n.jsx)(r.td,{children:"Aug 2021"}),(0,n.jsx)(r.td,{children:"178"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Jurassic-1: Technical Details and Evaluation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2107.02137v1",children:"ERNIE 3.0"})}),(0,n.jsx)(r.td,{children:"July 2021"}),(0,n.jsx)(r.td,{children:"10"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2107.03374v2",children:"Codex"})}),(0,n.jsx)(r.td,{children:"July 2021"}),(0,n.jsx)(r.td,{children:"12"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Evaluating Large Language Models Trained on Code"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/",children:"GPT-J-6B"})}),(0,n.jsx)(r.td,{children:"June 2021"}),(0,n.jsx)(r.td,{children:"6"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/kingoflolz/mesh-transformer-jax/#gpt-j-6b",children:"GPT-J-6B"})}),(0,n.jsx)(r.td,{children:"A 6 billion parameter, autoregressive text generation model trained on The Pile."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2106.10715v3",children:"CPM-2"})}),(0,n.jsx)(r.td,{children:"Jun 2021"}),(0,n.jsx)(r.td,{children:"198"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/TsinghuaAI/CPM",children:"CPM"})}),(0,n.jsx)(r.td,{children:"CPM-2: Large-scale Cost-effective Pre-trained Language Models"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2104.12369v1",children:"PanGu-α"})}),(0,n.jsx)(r.td,{children:"April 2021"}),(0,n.jsx)(r.td,{children:"13"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://gitee.com/mindspore/models/tree/master/official/nlp/Pangu_alpha#download-the-checkpoint",children:"PanGu-α"})}),(0,n.jsx)(r.td,{children:"PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2010.11934v3",children:"mT5"})}),(0,n.jsx)(r.td,{children:"Oct 2020"}),(0,n.jsx)(r.td,{children:"13"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/google-research/multilingual-t5#released-model-checkpoints",children:"mT5"})}),(0,n.jsx)(r.td,{children:"mT5: A massively multilingual pre-trained text-to-text transformer"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1910.13461",children:"BART"})}),(0,n.jsx)(r.td,{children:"Jul 2020"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/facebookresearch/fairseq",children:"BART"})}),(0,n.jsx)(r.td,{children:"Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2006.16668v1",children:"GShard"})}),(0,n.jsx)(r.td,{children:"Jun 2020"}),(0,n.jsx)(r.td,{children:"600"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/2005.14165",children:"GPT-3"})}),(0,n.jsx)(r.td,{children:"May 2020"}),(0,n.jsx)(r.td,{children:"175"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:"Language Models are Few-Shot Learners"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1909.05858",children:"CTRL"})}),(0,n.jsx)(r.td,{children:"Sep 2019"}),(0,n.jsx)(r.td,{children:"1.63"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/salesforce/ctrl",children:"CTRL"})}),(0,n.jsx)(r.td,{children:"CTRL: A Conditional Transformer Language Model for Controllable Generation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1909.11942",children:"ALBERT"})}),(0,n.jsx)(r.td,{children:"Sep 2019"}),(0,n.jsx)(r.td,{children:"0.235"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/google-research/ALBERT",children:"ALBERT"})}),(0,n.jsx)(r.td,{children:"A Lite BERT for Self-supervised Learning of Language Representations"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1906.08237",children:"XLNet"})}),(0,n.jsx)(r.td,{children:"Jun 2019"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/zihangdai/xlnet#released-models",children:"XLNet"})}),(0,n.jsx)(r.td,{children:"Generalized Autoregressive Pretraining for Language Understanding and Generation"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1910.10683",children:"T5"})}),(0,n.jsx)(r.td,{children:"Oct 2019"}),(0,n.jsx)(r.td,{children:"0.06 - 11"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints",children:"Flan-T5"})}),(0,n.jsx)(r.td,{children:"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf",children:"GPT-2"})}),(0,n.jsx)(r.td,{children:"Nov 2019"}),(0,n.jsx)(r.td,{children:"1.5"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/openai/gpt-2",children:"GPT-2"})}),(0,n.jsx)(r.td,{children:"Language Models are Unsupervised Multitask Learners"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1907.11692",children:"RoBERTa"})}),(0,n.jsx)(r.td,{children:"July 2019"}),(0,n.jsx)(r.td,{children:"0.125 - 0.355"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/facebookresearch/fairseq/tree/main/examples/roberta",children:"RoBERTa"})}),(0,n.jsx)(r.td,{children:"A Robustly Optimized BERT Pretraining Approach"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://arxiv.org/abs/1810.04805",children:"BERT"})}),(0,n.jsx)(r.td,{children:"Oct 2018"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/google-research/bert",children:"BERT"})}),(0,n.jsx)(r.td,{children:"Bidirectional Encoder Representations from Transformers"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf",children:"GPT"})}),(0,n.jsx)(r.td,{children:"June 2018"}),(0,n.jsx)(r.td,{children:"-"}),(0,n.jsx)(r.td,{children:(0,n.jsx)(r.a,{href:"https://github.com/openai/finetune-transformer-lm",children:"GPT"})}),(0,n.jsx)(r.td,{children:"Improving Language Understanding by Generative Pre-Training"})]})]})]}),"\n",(0,n.jsx)(l.UW,{emoji:"⚠️",children:(0,n.jsx)(r.p,{children:"Bu b\xf6l\xfcm geliştirme aşamasındadır."})}),"\n",(0,n.jsxs)(r.p,{children:["Veriler, ",(0,n.jsx)(r.a,{href:"https://paperswithcode.com/methods/category/language-models",children:"Papers with Code"})," ve ",(0,n.jsx)(r.a,{href:"https://arxiv.org/pdf/2303.18223.pdf",children:"Zhao ve diğerleri tarafından (2023)"})," yapılan yakın \xe7alışmalardan alınmıştır."]})]})}let o={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:r}=Object.assign({},(0,a.a)(),e.components);return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(h,{...e})}):h(e)},pageOpts:{filePath:"pages/models/collection.tr.mdx",route:"/models/collection",timestamp:1693344886e3,pageMap:[{kind:"Meta",locale:"tr",data:{index:"İstem M\xfchendisliği",introduction:"Giriş",techniques:"Teknikler",applications:"Uygulamalar",models:"Modeller",risks:"Riskler ve K\xf6t\xfcye Kullanımlar",papers:"Makaleler",tools:"Ara\xe7lar",notebooks:"Notlar",datasets:"Veri K\xfcmeleri",readings:"Ek Okumalar",course:{title:"İstem M\xfchendisliği Kursu",type:"page"},services:{title:"Hizmetler",type:"page"},about:{title:"Hakkında",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"tr"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"tr",data:{pal:"Program Destekli Dil Modelleri",generating:"Veri \xdcretimi",coding:"Kod \xdcretimi",workplace_casestudy:"Lisans\xfcst\xfc İş Sınıflandırması Vaka \xc7alışması",pf:"İstem Fonksiyonu"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"tr"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"tr"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"tr"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"tr"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"tr"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"tr"},{kind:"MdxPage",name:"course",route:"/course",locale:"tr"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"tr"},{kind:"MdxPage",name:"index",route:"/",locale:"tr"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"tr",data:{settings:"LLM Ayarları",basics:"İstemlerin Temelleri",elements:"Bir İstemin Unsurları",tips:"İstemlerin Tasarlanması İ\xe7in Genel İpu\xe7ları",examples:"\xd6rnek İstemler"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"tr"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"tr"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"tr"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"tr"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"tr"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"tr"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"tr",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"LLM Koleksiyonu"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"tr"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"tr"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"tr"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"tr"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"tr"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"tr"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"tr"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"tr"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"tr"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"tr"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"tr",data:{adversarial:"D\xfcşmanca İstemler",factuality:"Ger\xe7eklik",biases:"\xd6nyargılar"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"tr"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"tr"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"tr"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"tr"},{kind:"MdxPage",name:"services",route:"/services",locale:"tr"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"tr",data:{zeroshot:"Sıfır-\xd6rnekli İstem",fewshot:"Az-\xd6rnekli İstem",cot:"D\xfcş\xfcnce Zinciri İstemleri",consistency:"\xd6z-Tutarlılık",knowledge:"\xdcretilmiş Bilgi İstemleri",tot:"D\xfcş\xfcnce Ağacı",rag:"Veri Alımı Artırılmış \xdcretim",art:"Otomatik Akıl Y\xfcr\xfctme ve Ara\xe7 Kullanımı",ape:"Otomatik İstem M\xfchendisi",activeprompt:"Aktif-İstem",dsp:"Y\xf6nlendirici Uyarı İstemi",react:"ReAct",multimodalcot:"\xc7ok Modlu CoT İstemi",graph:"Grafik İstemi"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"tr"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"tr"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"tr"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"tr"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"tr"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"tr"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"tr"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"tr"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"tr"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"tr"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"tr"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"tr"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"tr"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"tr"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"tr"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"tr"}],flexsearch:{codeblocks:!0},title:"LLM Koleksiyonu",headings:c},pageNextRoute:"/models/collection.tr",nextraLayout:d.ZP,themeConfig:s.Z};r.default=(0,i.j)(o)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=48561)}),_N_E=e.O()}]);