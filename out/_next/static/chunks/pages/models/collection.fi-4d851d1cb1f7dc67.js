(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[11105],{44733:function(e,t,r){(window.__NEXT_P=window.__NEXT_P||[]).push(["/models/collection.fi",function(){return r(99740)}])},43677:function(e,t,r){"use strict";r.d(t,{Z:function(){return u}});var n=r(11527),i=r(50959),a=r(85274),s=r(5341);function d(e){return(0,n.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,n.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:t,className:r,...i}=e;return(0,n.jsx)("button",{className:(0,s.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",r),...i,children:t})};function o(e){return(0,n.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function c(e){return(0,n.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,n.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,n.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let h=e=>{let{getValue:t,...r}=e,[a,s]=(0,i.useState)(!1);(0,i.useEffect)(()=>{if(!a)return;let e=setTimeout(()=>{s(!1)},2e3);return()=>{clearTimeout(e)}},[a]);let d=(0,i.useCallback)(async()=>{s(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(t())}catch(e){console.error("Failed to copy!")}},[t]);return(0,n.jsx)(l,{onClick:d,title:"Copy code",tabIndex:0,...r,children:(0,n.jsx)(a?o:c,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},x=e=>{let{children:t,className:r,hasCopyCode:a=!0,filename:o,...c}=e,x=(0,i.useRef)(null),g=(0,i.useCallback)(()=>{let e=document.documentElement.dataset,t="nextraWordWrap"in e;t?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,n.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[o&&(0,n.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:o}),(0,n.jsx)("pre",{className:(0,s.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",o?"nx-pt-12 nx-pb-4":"nx-py-4",r),ref:x,...c,children:i.isValidElement(t)&&"code"===t.type?t.props.children:t}),(0,n.jsxs)("div",{className:(0,s.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",o?"nx-top-8":"nx-top-0"),children:[(0,n.jsx)(l,{onClick:g,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,n.jsx)(d,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),a&&(0,n.jsx)(h,{getValue(){var e,t;return(null===(e=null===(t=x.current)||void 0===t?void 0:t.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},g={logo:(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,n.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,n.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,n.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,a.ZR)();return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,n.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,n.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,n.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,n.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,n.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:x}};var u=g},99740:function(e,t,r){"use strict";r.r(t),r.d(t,{__toc:function(){return o}});var n=r(11527),i=r(55411),a=r(85274),s=r(43677);r(20492),r(95178);var d=r(82132),l=r(63622);let o=[{depth:2,value:"Models",id:"models"}];function c(e){let t=Object.assign({h1:"h1",p:"p",a:"a",h2:"h2",table:"table",thead:"thead",tr:"tr",th:"th",tbody:"tbody",td:"td"},(0,d.a)(),e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{children:"Kokoelma Kielimalleja"}),"\n","\n",(0,n.jsx)(l.UW,{emoji:"⚠️",children:(0,n.jsx)(t.p,{children:"T\xe4m\xe4 osa sivustoa kehittyy jatkuvasti."})}),"\n",(0,n.jsxs)(t.p,{children:["T\xe4ss\xe4 osio sis\xe4lt\xe4\xe4 kokoelman ja lyhyen tiivistelm\xe4n merkitt\xe4vist\xe4 kielimalleista. (Data koottu seuraavista l\xe4hteist\xe4: ",(0,n.jsx)(t.a,{href:"https://paperswithcode.com/methods/category/language-models",children:"Papers with Code"})," sek\xe4 ",(0,n.jsx)(t.a,{href:"https://arxiv.org/pdf/2303.18223.pdf",children:"Zhao ym. (2023)"}),"-julkaisusta.)"]}),"\n",(0,n.jsx)(t.h2,{id:"models",children:"Models"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Model"}),(0,n.jsx)(t.th,{children:"Release Date"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1810.04805",children:"BERT"})}),(0,n.jsx)(t.td,{children:"2018"}),(0,n.jsx)(t.td,{children:"Bidirectional Encoder Representations from Transformers"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf",children:"GPT"})}),(0,n.jsx)(t.td,{children:"2018"}),(0,n.jsx)(t.td,{children:"Improving Language Understanding by Generative Pre-Training"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1907.11692",children:"RoBERTa"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"A Robustly Optimized BERT Pretraining Approach"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf",children:"GPT-2"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"Language Models are Unsupervised Multitask Learners"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1910.10683",children:"T5"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1910.13461",children:"BART"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1909.11942",children:"ALBERT"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"A Lite BERT for Self-supervised Learning of Language Representations"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1906.08237",children:"XLNet"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"Generalized Autoregressive Pretraining for Language Understanding and Generation"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1909.05858",children:"CTRL"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"CTRL: A Conditional Transformer Language Model for Controllable Generation"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/1904.09223v1",children:"ERNIE"})}),(0,n.jsx)(t.td,{children:"2019"}),(0,n.jsx)(t.td,{children:"ERNIE: Enhanced Representation through Knowledge Integration"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2006.16668v1",children:"GShard"})}),(0,n.jsx)(t.td,{children:"2020"}),(0,n.jsx)(t.td,{children:"GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2005.14165",children:"GPT-3"})}),(0,n.jsx)(t.td,{children:"2020"}),(0,n.jsx)(t.td,{children:"Language Models are Few-Shot Learners"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2201.08239v3",children:"LaMDA"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"LaMDA: Language Models for Dialog Applications"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2104.12369v1",children:"PanGu-α"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2010.11934v3",children:"mT5"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"mT5: A massively multilingual pre-trained text-to-text transformer"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2106.10715v3",children:"CPM-2"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"CPM-2: Large-scale Cost-effective Pre-trained Language Models"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2110.08207",children:"T0"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Multitask Prompted Training Enables Zero-Shot Task Generalization"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2109.04650",children:"HyperCLOVA"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2107.03374v2",children:"Codex"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Evaluating Large Language Models Trained on Code"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2107.02137v1",children:"ERNIE 3.0"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"ERNIE 3.0: Large-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf",children:"Jurassic-1"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Jurassic-1: Technical Details and Evaluation"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2109.01652v5",children:"FLAN"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Finetuned Language Models Are Zero-Shot Learners"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2201.11990v3",children:"MT-NLG"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2110.04725v2",children:"Yuan 1.0"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2112.09332v3",children:"WebGPT"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"WebGPT: Browser-assisted question-answering with human feedback"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2112.11446v2",children:"Gopher"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"Scaling Language Models: Methods, Analysis & Insights from Training Gopher"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2112.12731v1",children:"ERNIE 3.0 Titan"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2112.06905",children:"GLaM"})}),(0,n.jsx)(t.td,{children:"2021"}),(0,n.jsx)(t.td,{children:"GLaM: Efficient Scaling of Language Models with Mixture-of-Experts"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2203.02155v1",children:"InstructGPT"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Training language models to follow instructions with human feedback"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2204.06745v1",children:"GPT-NeoX-20B"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"GPT-NeoX-20B: An Open-Source Autoregressive Language Model"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2203.07814v1",children:"AlphaCode"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Competition-Level Code Generation with AlphaCode"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2203.13474v5",children:"CodeGen"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2203.15556",children:"Chinchilla"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Shows that for a compute budget, the best performances are not achieved by the largest models but by smaller models trained on more data."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2204.07705v3",children:"Tk-Instruct"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2205.05131v3",children:"UL2"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"UL2: Unifying Language Learning Paradigms"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2204.02311v5",children:"PaLM"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"PaLM: Scaling Language Modeling with Pathways"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2205.01068",children:"OPT"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"OPT: Open Pre-trained Transformer Language Models"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2211.05100v3",children:"BLOOM"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2210.02414v1",children:"GLM-130B"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"GLM-130B: An Open Bilingual Pre-trained Model"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2208.01448v2",children:"AlexaTM"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2210.11416v5",children:"Flan-T5"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Scaling Instruction-Finetuned Language Models"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2209.14375",children:"Sparrow"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Improving alignment of dialogue agents via targeted human judgements"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2210.11399v2",children:"U-PaLM"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Transcending Scaling Laws with 0.1% Extra Compute"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2211.01786v1",children:"mT0"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Crosslingual Generalization through Multitask Finetuning"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2211.09085v1",children:"Galactica"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"Galactica: A Large Language Model for Science"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2212.12017v3",children:"OPT-IML"})}),(0,n.jsx)(t.td,{children:"2022"}),(0,n.jsx)(t.td,{children:"OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2302.13971v1",children:"LLaMA"})}),(0,n.jsx)(t.td,{children:"2023"}),(0,n.jsx)(t.td,{children:"LLaMA: Open and Efficient Foundation Language Models"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2303.08774v3",children:"GPT-4"})}),(0,n.jsx)(t.td,{children:"2023"}),(0,n.jsx)(t.td,{children:"GPT-4 Technical Report"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2303.10845v1",children:"PanGu-Σ"})}),(0,n.jsx)(t.td,{children:"2023"}),(0,n.jsx)(t.td,{children:"PanGu-Σ: Towards Trillion Parameter Language Model with Sparse Heterogeneous Computing"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2303.17564v1",children:"BloombergGPT"})}),(0,n.jsx)(t.td,{children:"2023"}),(0,n.jsx)(t.td,{children:"BloombergGPT: A Large Language Model for Finance"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2304.03208",children:"Cerebras-GPT"})}),(0,n.jsx)(t.td,{children:"2023"}),(0,n.jsx)(t.td,{children:"Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster"})]})]})]})]})}let h={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,d.a)(),e.components);return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(c,{...e})}):c(e)},pageOpts:{filePath:"pages/models/collection.fi.mdx",route:"/models/collection",pageMap:[{kind:"Meta",locale:"fi",data:{index:"Prompt Engineering",introduction:"Introduction",techniques:"Techniques",applications:"Applications",models:"Models",risks:"Risks & Misuses",papers:"Papers",tools:"Tools",notebooks:"Notebooks",datasets:"Datasets",readings:"Additional Readings",course:{title:"Prompt Engineering Course",type:"page"},services:{title:"Services",type:"page"},about:{title:"About",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"fi"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"fi",data:{pal:"Program-Aided Language Models",generating:"Generating Data",coding:"Generating Code",workplace_casestudy:"Graduate Job Classification Case Study",pf:"Prompt Function"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"fi"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"fi"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"fi"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"fi"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"fi"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"fi"},{kind:"MdxPage",name:"course",route:"/course",locale:"fi"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"fi"},{kind:"MdxPage",name:"index",route:"/",locale:"fi"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"fi",data:{settings:"LLM-asetukset",basics:"Kehottamisen perusteet",elements:"Kehotteiden elementit",tips:"Yleisi\xe4 vinkkej\xe4 kehotteiden suunnitteluun",examples:"Esimerkkej\xe4 kehotteista"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"fi"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"fi"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"fi"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"fi"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"fi"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"fi"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"fi",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"Model Collection"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"fi"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"fi"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"fi"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"fi"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"fi"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"fi"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"fi"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"fi"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"fi"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"fi"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"fi",data:{adversarial:"Adversarial Prompting",factuality:"Factuality",biases:"Biases"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"fi"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"fi"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"fi"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"fi"},{kind:"MdxPage",name:"services",route:"/services",locale:"fi"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"fi",data:{zeroshot:"Zero-shot Prompting",fewshot:"Few-shot Prompting",cot:"Chain-of-Thought Prompting",consistency:"Self-Consistency",knowledge:"Generate Knowledge Prompting",tot:"Tree of Thoughts",rag:"Retrieval Augmented Generation",art:"Automatic Reasoning and Tool-use",ape:"Automatic Prompt Engineer",activeprompt:"Active-Prompt",dsp:"Directional Stimulus Prompting",react:"ReAct",multimodalcot:"Multimodal CoT",graph:"Graph Prompting"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"fi"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"fi"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"fi"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"fi"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"fi"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"fi"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"fi"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"fi"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"fi"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"fi"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"fi"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"fi"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"fi"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"fi"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"fi"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"fi"}],flexsearch:{codeblocks:!0},title:"Kokoelma Kielimalleja",headings:o},pageNextRoute:"/models/collection.fi",nextraLayout:a.ZP,themeConfig:s.Z};t.default=(0,i.j)(h)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=44733)}),_N_E=e.O()}]);