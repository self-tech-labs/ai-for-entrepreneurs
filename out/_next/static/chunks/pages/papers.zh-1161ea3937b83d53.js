(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[82401],{2884:function(e,r,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/papers.zh",function(){return n(62893)}])},43677:function(e,r,n){"use strict";n.d(r,{Z:function(){return p}});var a=n(11527),i=n(50959),t=n(85274),s=n(5341);function o(e){return(0,a.jsx)("svg",{viewBox:"0 0 24 24",width:"24",height:"24",...e,children:(0,a.jsx)("path",{fill:"currentColor",d:"M4 19h6v-2H4v2zM20 5H4v2h16V5zm-3 6H4v2h13.25c1.1 0 2 .9 2 2s-.9 2-2 2H15v-2l-3 3l3 3v-2h2c2.21 0 4-1.79 4-4s-1.79-4-4-4z"})})}let l=e=>{let{children:r,className:n,...i}=e;return(0,a.jsx)("button",{className:(0,s.Z)("nextra-button nx-transition-all active:nx-opacity-50","nx-bg-primary-700/5 nx-border nx-border-black/5 nx-text-gray-600 hover:nx-text-gray-900 nx-rounded-md nx-p-1.5","dark:nx-bg-primary-300/10 dark:nx-border-white/10 dark:nx-text-gray-400 dark:hover:nx-text-gray-50",n),...i,children:r})};function h(e){return(0,a.jsx)("svg",{viewBox:"0 0 20 20",width:"1em",height:"1em",fill:"currentColor",...e,children:(0,a.jsx)("path",{fillRule:"evenodd",d:"M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z",clipRule:"evenodd"})})}function c(e){return(0,a.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",stroke:"currentColor",...e,children:[(0,a.jsx)("rect",{x:"9",y:"9",width:"13",height:"13",rx:"2",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"}),(0,a.jsx)("path",{d:"M5 15H4C2.89543 15 2 14.1046 2 13V4C2 2.89543 2.89543 2 4 2H13C14.1046 2 15 2.89543 15 4V5",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})]})}let d=e=>{let{getValue:r,...n}=e,[t,s]=(0,i.useState)(!1);(0,i.useEffect)(()=>{if(!t)return;let e=setTimeout(()=>{s(!1)},2e3);return()=>{clearTimeout(e)}},[t]);let o=(0,i.useCallback)(async()=>{s(!0),(null==navigator?void 0:navigator.clipboard)||console.error("Access to clipboard rejected!");try{await navigator.clipboard.writeText(r())}catch(e){console.error("Failed to copy!")}},[r]);return(0,a.jsx)(l,{onClick:o,title:"Copy code",tabIndex:0,...n,children:(0,a.jsx)(t?h:c,{className:"nextra-copy-icon nx-pointer-events-none nx-h-4 nx-w-4"})})},g=e=>{let{children:r,className:n,hasCopyCode:t=!0,filename:h,...c}=e,g=(0,i.useRef)(null),x=(0,i.useCallback)(()=>{let e=document.documentElement.dataset,r="nextraWordWrap"in e;r?delete e.nextraWordWrap:e.nextraWordWrap=""},[]);return(0,a.jsxs)("div",{className:"nextra-code-block nx-relative nx-mt-6 first:nx-mt-0",children:[h&&(0,a.jsx)("div",{className:"nx-absolute nx-top-0 nx-z-[1] nx-w-full nx-truncate nx-rounded-t-xl nx-bg-primary-700/5 nx-py-2 nx-px-4 nx-text-xs nx-text-gray-700 dark:nx-bg-primary-300/10 dark:nx-text-gray-200",children:h}),(0,a.jsx)("pre",{className:(0,s.Z)("nx-bg-primary-700/5 nx-mb-4 nx-overflow-x-auto nx-rounded-xl nx-subpixel-antialiased dark:nx-bg-primary-300/10 nx-text-[.9em]","contrast-more:nx-border contrast-more:nx-border-primary-900/20 contrast-more:nx-contrast-150 contrast-more:dark:nx-border-primary-100/40",h?"nx-pt-12 nx-pb-4":"nx-py-4",n),ref:g,...c,children:i.isValidElement(r)&&"code"===r.type?r.props.children:r}),(0,a.jsxs)("div",{className:(0,s.Z)("nx-opacity-0 nx-transition [div:hover>&]:nx-opacity-100 focus-within:nx-opacity-100","nx-flex nx-gap-1 nx-absolute nx-m-[11px] nx-right-0",h?"nx-top-8":"nx-top-0"),children:[(0,a.jsx)(l,{onClick:x,className:"md:nx-hidden",title:"Toggle word wrap elvis",children:(0,a.jsx)(o,{className:"nx-pointer-events-none nx-h-4 nx-w-4"})}),t&&(0,a.jsx)(d,{getValue(){var e,r;return(null===(e=null===(r=g.current)||void 0===r?void 0:r.querySelector("code"))||void 0===e?void 0:e.textContent)||""}})]})]})},x={logo:(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,a.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,a.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,a.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,a.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),i18n:[{locale:"en",text:"English"},{locale:"zh",text:"中文"},{locale:"jp",text:"日本語"},{locale:"pt",text:"Portugu\xeas"},{locale:"it",text:"Italian"},{locale:"tr",text:"T\xfcrk\xe7e"},{locale:"es",text:"Espa\xf1ol"},{locale:"fr",text:"Fran\xe7ais"},{locale:"kr",text:"한국어"},{locale:"ca",text:"Catal\xe0"},{locale:"fi",text:"Finnish"},{locale:"ru",text:"Русский"}],head:function(){let{title:e}=(0,t.ZR)();return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,a.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,a.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,a.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,a.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,a.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,a.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/FUyz9vPAwf"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"},search:{placeholder:"Search..."},components:{pre:g}};var p=x},62893:function(e,r,n){"use strict";n.r(r),n.d(r,{__toc:function(){return l}});var a=n(11527),i=n(55411),t=n(85274),s=n(43677);n(20492),n(95178);var o=n(82132);let l=[{depth:2,value:"综述",id:"综述"},{depth:2,value:"方法",id:"方法"},{depth:2,value:"应用",id:"应用"},{depth:2,value:"收集",id:"收集"}];function h(e){let r=Object.assign({h1:"h1",p:"p",h2:"h2",ul:"ul",li:"li",a:"a"},(0,o.a)(),e.components);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.h1,{children:"论文"}),"\n",(0,a.jsx)(r.p,{children:"以下是关于提示工程的最新论文（按发布日期排序）。我们每天更新，新论文不断涌现。我们每周将这些论文的摘要整合到上面的指南中。"}),"\n",(0,a.jsx)(r.h2,{id:"综述",children:"综述"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.14725",children:"Nature Language Reasoning, A Survey"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07842",children:"Augmented Language Models: a Survey"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2301.00234",children:"A Survey for In-context Learning"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.10403",children:"Towards Reasoning in Large Language Models: A Survey"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.09597",children:"Reasoning with Language Model Prompting: A Survey"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2206.07682",children:"Emergent Abilities of Large Language Models"})," (Jun 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2204.13988",children:"A Taxonomy of Prompt Modifiers for Text-To-Image Generation"})," (Apr 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2107.13586",children:"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"})," (Jul 2021)"]}),"\n"]}),"\n",(0,a.jsx)(r.h2,{id:"方法",children:"方法"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17651v1",children:"Self-Refine: Iterative Refinement with Self-Feedback"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13824",children:"kNN Prompting: Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13283",children:"Visual-Language Prompt Tuning with Knowledge-guided Context Optimization"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13217",children:"Fairness-guided Few-shot Prompting for Large Language Models"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.11315",children:"Context-faithful Prompting for Large Language Models"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.10475",children:"Is Prompt All You Need? No. A Comprehensive and Broader View of Instruction Learning"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.08518",children:"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.07320",children:"Model-tuning Via Prompts Makes NLP Models Adversarially Robust"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03922",children:"Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03628",children:"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation Verification"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03846",children:"Larger language models do in-context learning differently"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02913",children:"OpenICL: An Open-Source Framework for In-context Learning"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02909",children:"Dynamic Prompting: A Unified Framework for Prompt Tuning"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02861",children:"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02577",children:"Effectiveness of Data Augmentation for Prefix Tuning with Limited Data"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.01580",children:"Mixture of Soft Prompts for Controllable Data Generation"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.02151",children:"Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong Few-shot Learners"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.00293",children:"How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/pdf/2302.10198.pdf",children:"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and Fine-tuned BERT"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14838",children:"EvoPrompting: Language Models for Code-Level Neural Architecture Search"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14691",children:"In-Context Instruction Learning"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.02676",children:"Chain of Hindsight Aligns Language Models with Feedback"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14045",children:"Language Is Not All You Need: Aligning Perception with Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12822",children:"Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12246",children:"Active Prompting with Chain-of-Thought for Large Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12173",children:"More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.11382",children:"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.11520",children:"Guiding Large Language Models via Directional Stimulus Prompting"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.11521",children:"How Does In-Context Learning Help Prompt Tuning?"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.09236",children:"Scalable Prompt Generation for Semi-supervised Learning with Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.09185",children:"Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07994",children:"\xc0-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08043",children:"GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07459",children:"The Capacity for Moral Self-Correction in Large Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.06868",children:"SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.05619",children:"Evaluating the Robustness of Discrete Prompts"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.05698",children:"Compositional Exemplars for In-context Learning"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.03668",children:"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.00923",children:"Multimodal Chain-of-Thought Reasoning in Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.00093",children:"Large Language Models Can Be Easily Distracted by Irrelevant Context"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.00618",children:"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2301.12314",children:"Progressive Prompts: Continual Learning for Language Models"})," (Jan 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2301.08721",children:"Batch Prompting: Efficient Inference with LLM APIs"})," (Jan 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.14024",children:"Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.08061",children:"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.08073",children:"Constitutional AI: Harmlessness from AI Feedback"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.04092",children:"Successive Prompting for Decomposing Complex Questions"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.09561v1",children:"Large Language Models are reasoners with Self-Verification"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.09251",children:"Discovering Language Model Behaviors with Model-Written Evaluations"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.06713",children:"Structured Prompting: Scaling In-Context Learning to 1,000 Examples"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2211.10435",children:"PAL: Program-aided Language Models"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2211.01910",children:"Large Language Models Are Human-Level Prompt Engineers"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2211.09527",children:"Ignore Previous Prompt: Attack Techniques For Language Models"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.07321",children:"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2211.09066",children:"Teaching Algorithmic Reasoning via In-context Learning"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2211.11875",children:"Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://paperswithcode.com/paper/ask-me-anything-a-simple-strategy-for",children:"Ask Me Anything: A simple strategy for prompting language models"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.01296",children:"Recitation-Augmented Language Models"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.03629",children:"ReAct: Synergizing Reasoning and Acting in Language Models"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.09150",children:"Prompting GPT-3 To Be Reliable"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.02406",children:"Decomposed Prompting: A Modular Approach for Solving Complex Tasks"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.01240v3",children:"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2209.02128",children:"Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples"})," (Sep 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2209.14610",children:"Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning"})," (Sep 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2209.11755",children:"Promptagator: Few-shot Dense Retrieval From 8 Examples"})," (Sep 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2208.03299",children:"Atlas: Few-shot Learning with Retrieval Augmented Language Models"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2207.05987",children:"DocPrompting: Generating Code by Retrieving the Docs"})," (July 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2206.02336",children:"On the Advance of Making Language Models Better Reasoners"})," (June 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2205.11916",children:"Large Language Models are Zero-Shot Reasoners"})," (May 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2205.11822",children:"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations"})," (May 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2205.00445",children:"MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning"})," (May 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://aclanthology.org/2022.acl-long.576/",children:"PPT: Pre-trained Prompt Tuning for Few-shot Learning"})," (Mqy 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2205.12390",children:"Toxicity Detection with Generative Prompt-based Inference"})," (May 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2205.01543",children:"Learning to Transfer Prompts for Text Generation"})," (May 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2205.03401",children:"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning"})," (May 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2204.13988",children:"A Taxonomy of Prompt Modifiers for Text-To-Image Generation"})," (Apr 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2203.06566",children:"PromptChainer: Chaining Large Language Model Prompts through Visual Programming"})," (Mar 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2203.11171",children:"Self-Consistency Improves Chain of Thought Reasoning in Language Models"})," (March 2022)"]}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2203.02155",children:"Training language models to follow instructions with human feedback"})}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2202.12837",children:"Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?"})," (Feb 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2201.11903",children:"Chain of Thought Prompting Elicits Reasoning in Large Language Models"})," (Jan 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2112.00114",children:"Show Your Work: Scratchpads for Intermediate Computation with Language Models"})," (Nov 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2110.01691",children:"AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts"})," (Oct 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2110.08387",children:"Generated Knowledge Prompting for Commonsense Reasoning"})," (Oct 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2110.08207",children:"Multitask Prompted Training Enables Zero-Shot Task Generalization"})," (Oct 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2109.07830",children:"Reframing Instructional Prompts to GPTk's Language"})," (Sep 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2109.06977",children:"Design Guidelines for Prompt Engineering Text-to-Image Generative Models"})," (Sep 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://aclanthology.org/2021.acl-long.295",children:"Making Pre-trained Language Models Better Few-shot Learners"})," (Aug 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2104.08786",children:"Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"})," (April 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://aclanthology.org/2021.eacl-main.316",children:"BERTese: Learning to Speak to BERT"})," (April 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2104.08691",children:"The Power of Scale for Parameter-Efficient Prompt Tuning"})," (April 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2102.07350",children:"Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"})," (Feb 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2102.09690",children:"Calibrate Before Use: Improving Few-Shot Performance of Language Models"})," (Feb 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2101.00190",children:"Prefix-Tuning: Optimizing Continuous Prompts for Generation"})," (Jan 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2101.00420",children:"Learning to Generate Task-Specific Adapters from Task Description"})," (Jan 2021)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2012.15723",children:"Making Pre-trained Language Models Better Few-shot Learners"})," (Dec 2020)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://aclanthology.org/2020.emnlp-main.105/",children:"Learning from Task Descriptions"})," (Nov 2020)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2010.15980",children:"AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts"})," (Oct 2020)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2005.14165",children:"Language Models are Few-Shot Learners"})," (May 2020)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00324/96460/How-Can-We-Know-What-Language-Models-Know",children:"How Can We Know What Language Models Know?"})," (July 2020)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2001.08361",children:"Scaling Laws for Neural Language Models"})," (Jan 2020)"]}),"\n"]}),"\n",(0,a.jsx)(r.h2,{id:"应用",children:"应用"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://ai.google/static/documents/palm2techreport.pdf",children:"PaLM 2 Technical Report"})," (May 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17564",children:"BloombergGPT: A Large Language Model for Finance"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.17408",children:"Medical Intervention Duration Estimation Using Language-enhanced Transformer Encoder with Medical Prompts"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15846",children:"Soft-prompt tuning to predict lung cancer using primary care free-text Dutch medical notes"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.16434",children:"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.16445",children:"Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15587",children:"Linguistically Informed ChatGPT Prompts to Enhance Japanese-Chinese Machine Translation: A Case Study on Attributive Clauses"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.14375",children:"Knowledge-augmented Frame Semantic Parsing with Hybrid Prompt-tuning"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15413",children:"Debiasing Scores and Prompts of 2D Diffusion for Robust Text-to-3D Generation"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.15441#",children:"Zero-shot Model Diagnosis"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13592",children:"Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.13035",children:"SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.11455",children:"Large Language Models and Simple, Stupid Bugs"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.09325",children:"Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.08896",children:"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models"})," (Mar 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.05063",children:"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.05398",children:"MathPrompter: Mathematical Reasoning using Large Language Models"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.05400",children:"Prompt-Based Learning for Thread Structure Prediction in Cybersecurity Forums"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.03199",children:"Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.01903",children:"Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.00815",children:"Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2303.00733",children:"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks"})," (March 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14233",children:"Goal Driven Discovery of Distributional Differences via Language Descriptions"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.13439",children:"Navigating the Grey Area: Expressions of Overconfidence and Uncertainty in Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.14169",children:"TabGenie: A Toolkit for Table-to-Text Generation"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12449",children:"SGL-PT: A Strong Graph Learner with Graph Prompt Tuning"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12468",children:"Few-Shot Table-to-Text Generation with Prompt-based Adapter"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12692",children:"Language Models Are Few-shot Learners for Prognostic Prediction"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12784",children:"STA: Self-controlled Text Augmentation for Improving Text Classifications"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.12813",children:"Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.10916",children:"How Generative AI models such as ChatGPT can be (Mis)Used in SPC Practice, Education, and Research? An Exploratory Study"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08961",children:"Grimm in Wonderland: Prompt Engineering with Midjourney to Illustrate Fairytales"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08068",children:"LabelPrompt: Effective Prompt-based Learning for Relation Classification"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.09236",children:"Language Model Crossover: Variation through Few-Shot Prompting"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.08102",children:"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.07459",children:"The Capacity for Moral Self-Correction in Large Language Models"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.04156",children:"Prompting for Multimodal Hateful Meme Classification"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.03269",children:"PLACES: Prompting Language Models for Social Conversation Synthesis"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2302.01441",children:"Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation"})," (Feb 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2301.12810",children:"Crawling the Internal Knowledge-Base of Language Models"})," (Jan 2023)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2212.02199",children:"Legal Prompt Engineering for Multilingual Legal Judgement Prediction"})," (Dec 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2211.15462",children:"Investigating Prompt Engineering in Diffusion Models"})," (Nov 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2209.09513v2",children:"Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"})," (Sep 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.15157",children:"Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2210.14699",children:"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?"})," (Oct 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://aclanthology.org/2022.inlg-main.5",children:"Plot Writing From Scratch Pre-Trained Language Models"})," (July 2022)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.a,{href:"https://arxiv.org/abs/2202.03629",children:"Survey of Hallucination in Natural Language Generation"})," (Feb 2022)"]}),"\n"]}),"\n",(0,a.jsx)(r.h2,{id:"收集",children:"收集"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://github.com/Timothyxxx/Chain-of-ThoughtsPapers",children:"Chain-of-Thought Papers"})}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://paperswithcode.com/task/prompt-engineering",children:"Papers with Code"})}),"\n",(0,a.jsx)(r.li,{children:(0,a.jsx)(r.a,{href:"https://github.com/thunlp/PromptPapers#papers",children:"Prompt Papers"})}),"\n"]})]})}let c={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:r}=Object.assign({},(0,o.a)(),e.components);return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(h,{...e})}):h(e)},pageOpts:{filePath:"pages/papers.zh.mdx",route:"/papers",timestamp:1684273448e3,pageMap:[{kind:"Meta",locale:"zh",data:{index:"提示工程指南",introduction:"提示工程简介",techniques:"提示技术",applications:"提示应用",models:"模型",risks:"风险和误用",papers:"论文",tools:"工具和库",notebooks:"Prompt Engineering 笔记本",datasets:"数据集",readings:"阅读推荐",course:{title:"提示工程课程",type:"page"},services:{title:"服务",type:"page"},about:{title:"关于",type:"page"}}},{kind:"MdxPage",name:"about",route:"/about",locale:"zh"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",locale:"zh",data:{pal:"程序辅助语言模型",generating:"生成数据",coding:"Generating Code",workplace_casestudy:"毕业生工作分类案例研究",pf:"提示函数"}},{kind:"MdxPage",name:"coding",route:"/applications/coding",locale:"zh"},{kind:"MdxPage",name:"generating",route:"/applications/generating",locale:"zh"},{kind:"MdxPage",name:"pal",route:"/applications/pal",locale:"zh"},{kind:"MdxPage",name:"pf",route:"/applications/pf",locale:"zh"},{kind:"MdxPage",name:"workplace_casestudy",route:"/applications/workplace_casestudy",locale:"zh"},{kind:"MdxPage",name:"generating_textbooks",route:"/applications/generating_textbooks",locale:"en"},{kind:"MdxPage",name:"synthetic_rag",route:"/applications/synthetic_rag",locale:"en"}]},{kind:"MdxPage",name:"applications",route:"/applications",locale:"zh"},{kind:"MdxPage",name:"course",route:"/course",locale:"zh"},{kind:"MdxPage",name:"datasets",route:"/datasets",locale:"zh"},{kind:"MdxPage",name:"index",route:"/",locale:"zh"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",locale:"zh",data:{settings:"大语言模型设置",basics:"基本概念",elements:"提示词要素",tips:"设计提示的通用技巧",examples:"提示词示例"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics",locale:"zh"},{kind:"MdxPage",name:"elements",route:"/introduction/elements",locale:"zh"},{kind:"MdxPage",name:"examples",route:"/introduction/examples",locale:"zh"},{kind:"MdxPage",name:"settings",route:"/introduction/settings",locale:"zh"},{kind:"MdxPage",name:"tips",route:"/introduction/tips",locale:"zh"}]},{kind:"MdxPage",name:"introduction",route:"/introduction",locale:"zh"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",locale:"zh",data:{flan:"Flan",chatgpt:"ChatGPT",llama:"LLaMA","gpt-4":"GPT-4","mistral-7b":"Mistral 7B",collection:"Model Collection"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt",locale:"zh"},{kind:"MdxPage",name:"collection",route:"/models/collection",locale:"zh"},{kind:"MdxPage",name:"flan",route:"/models/flan",locale:"zh"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4",locale:"zh"},{kind:"MdxPage",name:"llama",route:"/models/llama",locale:"zh"},{kind:"MdxPage",name:"mistral-7b",route:"/models/mistral-7b",locale:"zh"}]},{kind:"MdxPage",name:"models",route:"/models",locale:"zh"},{kind:"MdxPage",name:"notebooks",route:"/notebooks",locale:"zh"},{kind:"MdxPage",name:"papers",route:"/papers",locale:"zh"},{kind:"MdxPage",name:"readings",route:"/readings",locale:"zh"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",locale:"zh",data:{adversarial:"对抗性提示",factuality:"真实性",biases:"偏见"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial",locale:"zh"},{kind:"MdxPage",name:"biases",route:"/risks/biases",locale:"zh"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality",locale:"zh"}]},{kind:"MdxPage",name:"risks",route:"/risks",locale:"zh"},{kind:"MdxPage",name:"services",route:"/services",locale:"zh"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",locale:"zh",data:{zeroshot:"零样本提示",fewshot:"少样本提示",cot:"链式思考（CoT）提示",consistency:"自我一致性",knowledge:"生成知识提示",tot:"思维树（ToT）",rag:"检索增强生成 (RAG)",art:"自动推理并使用工具（ART）",ape:"自动提示工程师",activeprompt:"Active-Prompt",dsp:"方向性刺激提示",react:"ReAct框架",multimodalcot:"多模态思维链提示方法",graph:"基于图的提示"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt",locale:"zh"},{kind:"MdxPage",name:"ape",route:"/techniques/ape",locale:"zh"},{kind:"MdxPage",name:"art",route:"/techniques/art",locale:"zh"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency",locale:"zh"},{kind:"MdxPage",name:"cot",route:"/techniques/cot",locale:"zh"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp",locale:"zh"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot",locale:"zh"},{kind:"MdxPage",name:"graph",route:"/techniques/graph",locale:"zh"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge",locale:"zh"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot",locale:"zh"},{kind:"MdxPage",name:"rag",route:"/techniques/rag",locale:"zh"},{kind:"MdxPage",name:"react",route:"/techniques/react",locale:"zh"},{kind:"MdxPage",name:"tot",route:"/techniques/tot",locale:"zh"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot",locale:"zh"}]},{kind:"MdxPage",name:"techniques",route:"/techniques",locale:"zh"},{kind:"MdxPage",name:"tools",route:"/tools",locale:"zh"}],flexsearch:{codeblocks:!0},title:"论文",headings:l},pageNextRoute:"/papers.zh",nextraLayout:t.ZP,themeConfig:s.Z};r.default=(0,i.j)(c)}},function(e){e.O(0,[67892,49774,92888,40179],function(){return e(e.s=2884)}),_N_E=e.O()}]);